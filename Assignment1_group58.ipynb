{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yonatandn/IDL/blob/develop/Assignment1_group58.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bhfIKbQzGq2"
      },
      "source": [
        "# Assignment 1. Music Century Classification\n",
        "\n",
        "**Assignment Responsible**: Natalie Lang.\n",
        "Te\n",
        "In this assignment, we will build models to predict which\n",
        "**century** a piece of music was released.  We will be using the \"YearPredictionMSD Data Set\"\n",
        "based on the Million Song Dataset. The data is available to download from the UCI \n",
        "Machine Learning Repository. Here are some links about the data:\n",
        "\n",
        "- https://archive.ics.uci.edu/ml/datasets/yearpredictionmsd\n",
        "- http://millionsongdataset.com/pages/tasks-demos/#yearrecognition\n",
        "\n",
        "Note that you are note allowed to import additional packages **(especially not PyTorch)**. One of the objectives is to understand how the training procedure actually operates, before working with PyTorch's autograd engine which does it all for us.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47oq1vy5PUIV"
      },
      "source": [
        "## Question 1. Data (21%)\n",
        "\n",
        "Start by setting up a Google Colab notebook in which to do your work.\n",
        "Since you are working with a partner, you might find this link helpful:\n",
        "\n",
        "- https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb\n",
        "\n",
        "The recommended way to work together is pair coding, where you and your partner are sitting together and writing code together. \n",
        "\n",
        "To process and read the data, we use the popular `pandas` package for data analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aFWpuNSzGq9"
      },
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7UWL6mFzGq-"
      },
      "source": [
        "Now that your notebook is set up, we can load the data into the notebook. The code below provides\n",
        "two ways of loading the data: directly from the internet, or through mounting Google Drive.\n",
        "The first method is easier but slower, and the second method is a bit involved at first, but\n",
        "can save you time later on. You will need to mount Google Drive for later assignments, so we recommend\n",
        "figuring how to do that now.\n",
        "\n",
        "Here are some resources to help you get started:\n",
        "\n",
        "- http.://colab.research.google.com/notebooks/io.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY6PrfV4zGq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89683c1e-edf1-4cea-a93b-59f8f84c5068"
      },
      "source": [
        "load_from_drive = True\n",
        "\n",
        "if not load_from_drive:\n",
        "  csv_path = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\"\n",
        "else:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  csv_path = '/content/gdrive/MyDrive/IDL_Data/YearPredictionMSD.txt.zip' \n",
        "\n",
        "t_label = [\"year\"]\n",
        "x_labels = [\"var%d\" % i for i in range(1, 91)]\n",
        "df = pandas.read_csv(csv_path, names=t_label + x_labels)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgB83beNzGq_"
      },
      "source": [
        "Now that the data is loaded to your Colab notebook, you should be able to display the Pandas\n",
        "DataFrame `df` as a table:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5bBEnj3zGq_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "fc02a9ef-3c68-426c-cdaa-f16b9ec71440"
      },
      "source": [
        "df"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        year      var1      var2      var3      var4      var5      var6  \\\n",
              "0       2001  49.94357  21.47114  73.07750   8.74861 -17.40628 -13.09905   \n",
              "1       2001  48.73215  18.42930  70.32679  12.94636 -10.32437 -24.83777   \n",
              "2       2001  50.95714  31.85602  55.81851  13.41693  -6.57898 -18.54940   \n",
              "3       2001  48.24750  -1.89837  36.29772   2.58776   0.97170 -26.21683   \n",
              "4       2001  50.97020  42.20998  67.09964   8.46791 -15.85279 -16.81409   \n",
              "...      ...       ...       ...       ...       ...       ...       ...   \n",
              "515340  2006  51.28467  45.88068  22.19582  -5.53319  -3.61835 -16.36914   \n",
              "515341  2006  49.87870  37.93125  18.65987  -3.63581 -27.75665 -18.52988   \n",
              "515342  2006  45.12852  12.65758 -38.72018   8.80882 -29.29985  -2.28706   \n",
              "515343  2006  44.16614  32.38368  -3.34971  -2.49165 -19.59278 -18.67098   \n",
              "515344  2005  51.85726  59.11655  26.39436  -5.46030 -20.69012 -19.95528   \n",
              "\n",
              "            var7      var8      var9  ...     var81      var82      var83  \\\n",
              "0      -25.01202 -12.23257   7.83089  ...  13.01620  -54.40548   58.99367   \n",
              "1        8.76630  -0.92019  18.76548  ...   5.66812  -19.68073   33.04964   \n",
              "2       -3.27872  -2.35035  16.07017  ...   3.03800   26.05866  -50.92779   \n",
              "3        5.05097 -10.34124   3.55005  ...  34.57337 -171.70734  -16.96705   \n",
              "4      -12.48207  -9.37636  12.63699  ...   9.92661  -55.95724   64.92712   \n",
              "...          ...       ...       ...  ...       ...        ...        ...   \n",
              "515340   2.12652   5.18160  -8.66890  ...   4.81440   -3.75991  -30.92584   \n",
              "515341   7.76108   3.56109  -2.50351  ...  32.38589  -32.75535  -61.05473   \n",
              "515342 -18.40424 -22.28726  -4.52429  ... -18.73598  -71.15954 -123.98443   \n",
              "515343   8.78428   4.02039 -12.01230  ...  67.16763  282.77624   -4.63677   \n",
              "515344  -6.72771   2.29590  10.31018  ... -11.50511  -69.18291   60.58456   \n",
              "\n",
              "            var84     var85     var86      var87     var88      var89  \\\n",
              "0        15.37344   1.11144 -23.08793   68.40795  -1.82223  -27.46348   \n",
              "1        42.87836  -9.90378 -32.22788   70.49388  12.04941   58.43453   \n",
              "2        10.93792  -0.07568  43.20130 -115.00698  -0.05859   39.67068   \n",
              "3       -46.67617 -12.51516  82.58061  -72.08993   9.90558  199.62971   \n",
              "4       -17.72522  -1.49237  -7.50035   51.76631   7.88713   55.66926   \n",
              "...           ...       ...       ...        ...       ...        ...   \n",
              "515340   26.33968  -5.03390  21.86037 -142.29410   3.42901  -41.14721   \n",
              "515341   56.65182  15.29965  95.88193  -10.63242  12.96552   92.11633   \n",
              "515342  121.26989  10.89629  34.62409 -248.61020  -6.07171   53.96319   \n",
              "515343  144.00125  21.62652 -29.72432   71.47198  20.32240   14.83107   \n",
              "515344   28.64599  -4.39620 -64.56491  -45.61012  -5.51512   32.35602   \n",
              "\n",
              "           var90  \n",
              "0        2.26327  \n",
              "1       26.92061  \n",
              "2       -0.66345  \n",
              "3       18.85382  \n",
              "4       28.74903  \n",
              "...          ...  \n",
              "515340 -15.46052  \n",
              "515341  10.88815  \n",
              "515342  -8.09364  \n",
              "515343  39.74909  \n",
              "515344  12.17352  \n",
              "\n",
              "[515345 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14910711-f64c-4eea-a1ea-58a96cc5ec3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>var3</th>\n",
              "      <th>var4</th>\n",
              "      <th>var5</th>\n",
              "      <th>var6</th>\n",
              "      <th>var7</th>\n",
              "      <th>var8</th>\n",
              "      <th>var9</th>\n",
              "      <th>...</th>\n",
              "      <th>var81</th>\n",
              "      <th>var82</th>\n",
              "      <th>var83</th>\n",
              "      <th>var84</th>\n",
              "      <th>var85</th>\n",
              "      <th>var86</th>\n",
              "      <th>var87</th>\n",
              "      <th>var88</th>\n",
              "      <th>var89</th>\n",
              "      <th>var90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515340</th>\n",
              "      <td>2006</td>\n",
              "      <td>51.28467</td>\n",
              "      <td>45.88068</td>\n",
              "      <td>22.19582</td>\n",
              "      <td>-5.53319</td>\n",
              "      <td>-3.61835</td>\n",
              "      <td>-16.36914</td>\n",
              "      <td>2.12652</td>\n",
              "      <td>5.18160</td>\n",
              "      <td>-8.66890</td>\n",
              "      <td>...</td>\n",
              "      <td>4.81440</td>\n",
              "      <td>-3.75991</td>\n",
              "      <td>-30.92584</td>\n",
              "      <td>26.33968</td>\n",
              "      <td>-5.03390</td>\n",
              "      <td>21.86037</td>\n",
              "      <td>-142.29410</td>\n",
              "      <td>3.42901</td>\n",
              "      <td>-41.14721</td>\n",
              "      <td>-15.46052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515341</th>\n",
              "      <td>2006</td>\n",
              "      <td>49.87870</td>\n",
              "      <td>37.93125</td>\n",
              "      <td>18.65987</td>\n",
              "      <td>-3.63581</td>\n",
              "      <td>-27.75665</td>\n",
              "      <td>-18.52988</td>\n",
              "      <td>7.76108</td>\n",
              "      <td>3.56109</td>\n",
              "      <td>-2.50351</td>\n",
              "      <td>...</td>\n",
              "      <td>32.38589</td>\n",
              "      <td>-32.75535</td>\n",
              "      <td>-61.05473</td>\n",
              "      <td>56.65182</td>\n",
              "      <td>15.29965</td>\n",
              "      <td>95.88193</td>\n",
              "      <td>-10.63242</td>\n",
              "      <td>12.96552</td>\n",
              "      <td>92.11633</td>\n",
              "      <td>10.88815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515342</th>\n",
              "      <td>2006</td>\n",
              "      <td>45.12852</td>\n",
              "      <td>12.65758</td>\n",
              "      <td>-38.72018</td>\n",
              "      <td>8.80882</td>\n",
              "      <td>-29.29985</td>\n",
              "      <td>-2.28706</td>\n",
              "      <td>-18.40424</td>\n",
              "      <td>-22.28726</td>\n",
              "      <td>-4.52429</td>\n",
              "      <td>...</td>\n",
              "      <td>-18.73598</td>\n",
              "      <td>-71.15954</td>\n",
              "      <td>-123.98443</td>\n",
              "      <td>121.26989</td>\n",
              "      <td>10.89629</td>\n",
              "      <td>34.62409</td>\n",
              "      <td>-248.61020</td>\n",
              "      <td>-6.07171</td>\n",
              "      <td>53.96319</td>\n",
              "      <td>-8.09364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515343</th>\n",
              "      <td>2006</td>\n",
              "      <td>44.16614</td>\n",
              "      <td>32.38368</td>\n",
              "      <td>-3.34971</td>\n",
              "      <td>-2.49165</td>\n",
              "      <td>-19.59278</td>\n",
              "      <td>-18.67098</td>\n",
              "      <td>8.78428</td>\n",
              "      <td>4.02039</td>\n",
              "      <td>-12.01230</td>\n",
              "      <td>...</td>\n",
              "      <td>67.16763</td>\n",
              "      <td>282.77624</td>\n",
              "      <td>-4.63677</td>\n",
              "      <td>144.00125</td>\n",
              "      <td>21.62652</td>\n",
              "      <td>-29.72432</td>\n",
              "      <td>71.47198</td>\n",
              "      <td>20.32240</td>\n",
              "      <td>14.83107</td>\n",
              "      <td>39.74909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515344</th>\n",
              "      <td>2005</td>\n",
              "      <td>51.85726</td>\n",
              "      <td>59.11655</td>\n",
              "      <td>26.39436</td>\n",
              "      <td>-5.46030</td>\n",
              "      <td>-20.69012</td>\n",
              "      <td>-19.95528</td>\n",
              "      <td>-6.72771</td>\n",
              "      <td>2.29590</td>\n",
              "      <td>10.31018</td>\n",
              "      <td>...</td>\n",
              "      <td>-11.50511</td>\n",
              "      <td>-69.18291</td>\n",
              "      <td>60.58456</td>\n",
              "      <td>28.64599</td>\n",
              "      <td>-4.39620</td>\n",
              "      <td>-64.56491</td>\n",
              "      <td>-45.61012</td>\n",
              "      <td>-5.51512</td>\n",
              "      <td>32.35602</td>\n",
              "      <td>12.17352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>515345 rows × 91 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14910711-f64c-4eea-a1ea-58a96cc5ec3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14910711-f64c-4eea-a1ea-58a96cc5ec3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14910711-f64c-4eea-a1ea-58a96cc5ec3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaLuAMH_zGrA"
      },
      "source": [
        "To set up our data for classification, we'll use the \"year\" field to represent\n",
        "whether a song was released in the 20-th century. In our case `df[\"year\"]` will be 1 if\n",
        "the year was released after 2000, and 0 otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZdGlNgdzGrA"
      },
      "source": [
        "df[\"year\"] = df[\"year\"].map(lambda x: int(x > 2000))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xugy7FZ8eoAd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "outputId": "8d4583c5-9fa8-48a6-da43-5ce83573aff2"
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    year      var1       var2      var3      var4      var5      var6  \\\n",
              "0      1  49.94357   21.47114  73.07750   8.74861 -17.40628 -13.09905   \n",
              "1      1  48.73215   18.42930  70.32679  12.94636 -10.32437 -24.83777   \n",
              "2      1  50.95714   31.85602  55.81851  13.41693  -6.57898 -18.54940   \n",
              "3      1  48.24750   -1.89837  36.29772   2.58776   0.97170 -26.21683   \n",
              "4      1  50.97020   42.20998  67.09964   8.46791 -15.85279 -16.81409   \n",
              "5      1  50.54767    0.31568  92.35066  22.38696 -25.51870 -19.04928   \n",
              "6      1  50.57546   33.17843  50.53517  11.55217 -27.24764  -8.78206   \n",
              "7      1  48.26892    8.97526  75.23158  24.04945 -16.02105 -14.09491   \n",
              "8      1  49.75468   33.99581  56.73846   2.89581  -2.92429 -26.44413   \n",
              "9      1  45.17809   46.34234 -40.65357  -2.47909   1.21253  -0.65302   \n",
              "10     1  39.13076  -23.01763 -36.20583   1.67519  -4.27101  13.01158   \n",
              "11     1  37.66498  -34.05910 -17.36060 -26.77781 -39.95119 -20.75000   \n",
              "12     1  26.51957 -148.15762 -13.30095  -7.25851  17.22029 -21.99439   \n",
              "13     1  37.68491  -26.84185 -27.10566 -14.95883  -5.87200 -21.68979   \n",
              "14     0  39.11695   -8.29767 -51.37966  -4.42668 -30.06506 -11.95916   \n",
              "15     1  35.05129  -67.97714 -14.20239  -6.68696  -0.61230 -18.70341   \n",
              "16     1  33.63129  -96.14912 -89.38216 -12.11699  13.77252  -6.69377   \n",
              "17     0  41.38639  -20.78665  51.80155  17.21415 -36.44189 -11.53169   \n",
              "18     0  37.45034   11.42615  56.28982  19.58426 -16.43530   2.22457   \n",
              "19     0  39.71092   -4.92800  12.88590 -11.87773   2.48031 -16.11028   \n",
              "\n",
              "        var7      var8      var9  ...     var81      var82      var83  \\\n",
              "0  -25.01202 -12.23257   7.83089  ...  13.01620  -54.40548   58.99367   \n",
              "1    8.76630  -0.92019  18.76548  ...   5.66812  -19.68073   33.04964   \n",
              "2   -3.27872  -2.35035  16.07017  ...   3.03800   26.05866  -50.92779   \n",
              "3    5.05097 -10.34124   3.55005  ...  34.57337 -171.70734  -16.96705   \n",
              "4  -12.48207  -9.37636  12.63699  ...   9.92661  -55.95724   64.92712   \n",
              "5   20.67345  -5.19943   3.63566  ...   6.59753  -50.69577   26.02574   \n",
              "6  -12.04282  -9.53930  28.61811  ...  11.63681   25.44182  134.62382   \n",
              "7    8.11871  -1.87566   7.46701  ...  18.03989  -58.46192  -65.56438   \n",
              "8    1.71392  -0.55644  22.08594  ...  18.70812    5.20391  -27.75192   \n",
              "9   -6.95536 -12.20040  17.02512  ...  -4.36742  -87.55285  -70.79677   \n",
              "10   8.05718  -8.41088   6.27370  ...  32.86051  -26.08461 -186.82429   \n",
              "11  -0.10231  -0.89972  -1.30205  ...  11.18909   45.20614   53.83925   \n",
              "12   5.51947   3.48418   2.61738  ...  23.80442  251.76360   18.81642   \n",
              "13   4.87374 -18.01800   1.52141  ... -67.57637  234.27192  -72.34557   \n",
              "14  -0.85322  -8.86179  11.36680  ...  42.22923  478.26580  -10.33823   \n",
              "15  -1.31928  -9.46370   5.53492  ...  10.25585   94.90539   15.95689   \n",
              "16 -33.36843 -24.81437  21.22757  ...  49.93249  -14.47489   40.70590   \n",
              "17  11.75252  -7.62428  -3.65488  ...  50.37614  -40.48205   48.07805   \n",
              "18   1.02668  -7.34736  -0.01184  ... -22.46207  -25.77228 -322.42841   \n",
              "19 -16.40421  -8.29657   9.86817  ...  11.92816  -73.72412   16.19039   \n",
              "\n",
              "        var84     var85      var86      var87     var88       var89     var90  \n",
              "0    15.37344   1.11144  -23.08793   68.40795  -1.82223   -27.46348   2.26327  \n",
              "1    42.87836  -9.90378  -32.22788   70.49388  12.04941    58.43453  26.92061  \n",
              "2    10.93792  -0.07568   43.20130 -115.00698  -0.05859    39.67068  -0.66345  \n",
              "3   -46.67617 -12.51516   82.58061  -72.08993   9.90558   199.62971  18.85382  \n",
              "4   -17.72522  -1.49237   -7.50035   51.76631   7.88713    55.66926  28.74903  \n",
              "5    18.94430  -0.33730    6.09352   35.18381   5.00283   -11.02257   0.02263  \n",
              "6    21.51982   8.17570   35.46251   11.57736   4.50056    -4.62739   1.40192  \n",
              "7    46.99856  -4.09602   56.37650  -18.29975  -0.30633     3.98364  -3.72556  \n",
              "8    17.22100  -0.85210  -15.67150  -26.36257   5.48708    -9.13495   6.08680  \n",
              "9    76.57355  -7.71727    3.26926 -298.49845  11.49326   -89.21804 -15.09719  \n",
              "10  113.58176   9.28727   44.60282  158.00425  -2.59543   109.19723  23.36143  \n",
              "11    2.59467  -4.00958  -47.74886 -170.92864  -5.19009     8.83617  -7.16056  \n",
              "12  157.09656 -27.79449 -137.72740  115.28414  23.00230  -164.02536  51.54138  \n",
              "13 -362.25101 -25.55019  -89.08971 -891.58937  14.11648 -1030.99180  99.28967  \n",
              "14 -103.76858  39.19511  -98.76636 -122.81061  -2.14942  -211.48202 -12.81569  \n",
              "15  -98.15732  -9.64859  -93.52834  -95.82981  20.73063  -562.07671  43.44696  \n",
              "16   58.63692   8.81522   27.28474    5.78046   3.44539   259.10825  10.28525  \n",
              "17   -7.62399   6.51934  -30.46090  -53.87264   4.44627    58.16913  -0.02409  \n",
              "18 -146.57408  13.61588   92.22918 -439.80259  25.73235   157.22967  38.70617  \n",
              "19    9.79606   9.71693   -9.90907  -20.65851   2.34002   -31.57015   1.58400  \n",
              "\n",
              "[20 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f4864a8-eda9-4b40-8017-51d4d424818d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>var3</th>\n",
              "      <th>var4</th>\n",
              "      <th>var5</th>\n",
              "      <th>var6</th>\n",
              "      <th>var7</th>\n",
              "      <th>var8</th>\n",
              "      <th>var9</th>\n",
              "      <th>...</th>\n",
              "      <th>var81</th>\n",
              "      <th>var82</th>\n",
              "      <th>var83</th>\n",
              "      <th>var84</th>\n",
              "      <th>var85</th>\n",
              "      <th>var86</th>\n",
              "      <th>var87</th>\n",
              "      <th>var88</th>\n",
              "      <th>var89</th>\n",
              "      <th>var90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>50.54767</td>\n",
              "      <td>0.31568</td>\n",
              "      <td>92.35066</td>\n",
              "      <td>22.38696</td>\n",
              "      <td>-25.51870</td>\n",
              "      <td>-19.04928</td>\n",
              "      <td>20.67345</td>\n",
              "      <td>-5.19943</td>\n",
              "      <td>3.63566</td>\n",
              "      <td>...</td>\n",
              "      <td>6.59753</td>\n",
              "      <td>-50.69577</td>\n",
              "      <td>26.02574</td>\n",
              "      <td>18.94430</td>\n",
              "      <td>-0.33730</td>\n",
              "      <td>6.09352</td>\n",
              "      <td>35.18381</td>\n",
              "      <td>5.00283</td>\n",
              "      <td>-11.02257</td>\n",
              "      <td>0.02263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>50.57546</td>\n",
              "      <td>33.17843</td>\n",
              "      <td>50.53517</td>\n",
              "      <td>11.55217</td>\n",
              "      <td>-27.24764</td>\n",
              "      <td>-8.78206</td>\n",
              "      <td>-12.04282</td>\n",
              "      <td>-9.53930</td>\n",
              "      <td>28.61811</td>\n",
              "      <td>...</td>\n",
              "      <td>11.63681</td>\n",
              "      <td>25.44182</td>\n",
              "      <td>134.62382</td>\n",
              "      <td>21.51982</td>\n",
              "      <td>8.17570</td>\n",
              "      <td>35.46251</td>\n",
              "      <td>11.57736</td>\n",
              "      <td>4.50056</td>\n",
              "      <td>-4.62739</td>\n",
              "      <td>1.40192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>48.26892</td>\n",
              "      <td>8.97526</td>\n",
              "      <td>75.23158</td>\n",
              "      <td>24.04945</td>\n",
              "      <td>-16.02105</td>\n",
              "      <td>-14.09491</td>\n",
              "      <td>8.11871</td>\n",
              "      <td>-1.87566</td>\n",
              "      <td>7.46701</td>\n",
              "      <td>...</td>\n",
              "      <td>18.03989</td>\n",
              "      <td>-58.46192</td>\n",
              "      <td>-65.56438</td>\n",
              "      <td>46.99856</td>\n",
              "      <td>-4.09602</td>\n",
              "      <td>56.37650</td>\n",
              "      <td>-18.29975</td>\n",
              "      <td>-0.30633</td>\n",
              "      <td>3.98364</td>\n",
              "      <td>-3.72556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>49.75468</td>\n",
              "      <td>33.99581</td>\n",
              "      <td>56.73846</td>\n",
              "      <td>2.89581</td>\n",
              "      <td>-2.92429</td>\n",
              "      <td>-26.44413</td>\n",
              "      <td>1.71392</td>\n",
              "      <td>-0.55644</td>\n",
              "      <td>22.08594</td>\n",
              "      <td>...</td>\n",
              "      <td>18.70812</td>\n",
              "      <td>5.20391</td>\n",
              "      <td>-27.75192</td>\n",
              "      <td>17.22100</td>\n",
              "      <td>-0.85210</td>\n",
              "      <td>-15.67150</td>\n",
              "      <td>-26.36257</td>\n",
              "      <td>5.48708</td>\n",
              "      <td>-9.13495</td>\n",
              "      <td>6.08680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>45.17809</td>\n",
              "      <td>46.34234</td>\n",
              "      <td>-40.65357</td>\n",
              "      <td>-2.47909</td>\n",
              "      <td>1.21253</td>\n",
              "      <td>-0.65302</td>\n",
              "      <td>-6.95536</td>\n",
              "      <td>-12.20040</td>\n",
              "      <td>17.02512</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.36742</td>\n",
              "      <td>-87.55285</td>\n",
              "      <td>-70.79677</td>\n",
              "      <td>76.57355</td>\n",
              "      <td>-7.71727</td>\n",
              "      <td>3.26926</td>\n",
              "      <td>-298.49845</td>\n",
              "      <td>11.49326</td>\n",
              "      <td>-89.21804</td>\n",
              "      <td>-15.09719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>39.13076</td>\n",
              "      <td>-23.01763</td>\n",
              "      <td>-36.20583</td>\n",
              "      <td>1.67519</td>\n",
              "      <td>-4.27101</td>\n",
              "      <td>13.01158</td>\n",
              "      <td>8.05718</td>\n",
              "      <td>-8.41088</td>\n",
              "      <td>6.27370</td>\n",
              "      <td>...</td>\n",
              "      <td>32.86051</td>\n",
              "      <td>-26.08461</td>\n",
              "      <td>-186.82429</td>\n",
              "      <td>113.58176</td>\n",
              "      <td>9.28727</td>\n",
              "      <td>44.60282</td>\n",
              "      <td>158.00425</td>\n",
              "      <td>-2.59543</td>\n",
              "      <td>109.19723</td>\n",
              "      <td>23.36143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>37.66498</td>\n",
              "      <td>-34.05910</td>\n",
              "      <td>-17.36060</td>\n",
              "      <td>-26.77781</td>\n",
              "      <td>-39.95119</td>\n",
              "      <td>-20.75000</td>\n",
              "      <td>-0.10231</td>\n",
              "      <td>-0.89972</td>\n",
              "      <td>-1.30205</td>\n",
              "      <td>...</td>\n",
              "      <td>11.18909</td>\n",
              "      <td>45.20614</td>\n",
              "      <td>53.83925</td>\n",
              "      <td>2.59467</td>\n",
              "      <td>-4.00958</td>\n",
              "      <td>-47.74886</td>\n",
              "      <td>-170.92864</td>\n",
              "      <td>-5.19009</td>\n",
              "      <td>8.83617</td>\n",
              "      <td>-7.16056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>26.51957</td>\n",
              "      <td>-148.15762</td>\n",
              "      <td>-13.30095</td>\n",
              "      <td>-7.25851</td>\n",
              "      <td>17.22029</td>\n",
              "      <td>-21.99439</td>\n",
              "      <td>5.51947</td>\n",
              "      <td>3.48418</td>\n",
              "      <td>2.61738</td>\n",
              "      <td>...</td>\n",
              "      <td>23.80442</td>\n",
              "      <td>251.76360</td>\n",
              "      <td>18.81642</td>\n",
              "      <td>157.09656</td>\n",
              "      <td>-27.79449</td>\n",
              "      <td>-137.72740</td>\n",
              "      <td>115.28414</td>\n",
              "      <td>23.00230</td>\n",
              "      <td>-164.02536</td>\n",
              "      <td>51.54138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>37.68491</td>\n",
              "      <td>-26.84185</td>\n",
              "      <td>-27.10566</td>\n",
              "      <td>-14.95883</td>\n",
              "      <td>-5.87200</td>\n",
              "      <td>-21.68979</td>\n",
              "      <td>4.87374</td>\n",
              "      <td>-18.01800</td>\n",
              "      <td>1.52141</td>\n",
              "      <td>...</td>\n",
              "      <td>-67.57637</td>\n",
              "      <td>234.27192</td>\n",
              "      <td>-72.34557</td>\n",
              "      <td>-362.25101</td>\n",
              "      <td>-25.55019</td>\n",
              "      <td>-89.08971</td>\n",
              "      <td>-891.58937</td>\n",
              "      <td>14.11648</td>\n",
              "      <td>-1030.99180</td>\n",
              "      <td>99.28967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>39.11695</td>\n",
              "      <td>-8.29767</td>\n",
              "      <td>-51.37966</td>\n",
              "      <td>-4.42668</td>\n",
              "      <td>-30.06506</td>\n",
              "      <td>-11.95916</td>\n",
              "      <td>-0.85322</td>\n",
              "      <td>-8.86179</td>\n",
              "      <td>11.36680</td>\n",
              "      <td>...</td>\n",
              "      <td>42.22923</td>\n",
              "      <td>478.26580</td>\n",
              "      <td>-10.33823</td>\n",
              "      <td>-103.76858</td>\n",
              "      <td>39.19511</td>\n",
              "      <td>-98.76636</td>\n",
              "      <td>-122.81061</td>\n",
              "      <td>-2.14942</td>\n",
              "      <td>-211.48202</td>\n",
              "      <td>-12.81569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>35.05129</td>\n",
              "      <td>-67.97714</td>\n",
              "      <td>-14.20239</td>\n",
              "      <td>-6.68696</td>\n",
              "      <td>-0.61230</td>\n",
              "      <td>-18.70341</td>\n",
              "      <td>-1.31928</td>\n",
              "      <td>-9.46370</td>\n",
              "      <td>5.53492</td>\n",
              "      <td>...</td>\n",
              "      <td>10.25585</td>\n",
              "      <td>94.90539</td>\n",
              "      <td>15.95689</td>\n",
              "      <td>-98.15732</td>\n",
              "      <td>-9.64859</td>\n",
              "      <td>-93.52834</td>\n",
              "      <td>-95.82981</td>\n",
              "      <td>20.73063</td>\n",
              "      <td>-562.07671</td>\n",
              "      <td>43.44696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>33.63129</td>\n",
              "      <td>-96.14912</td>\n",
              "      <td>-89.38216</td>\n",
              "      <td>-12.11699</td>\n",
              "      <td>13.77252</td>\n",
              "      <td>-6.69377</td>\n",
              "      <td>-33.36843</td>\n",
              "      <td>-24.81437</td>\n",
              "      <td>21.22757</td>\n",
              "      <td>...</td>\n",
              "      <td>49.93249</td>\n",
              "      <td>-14.47489</td>\n",
              "      <td>40.70590</td>\n",
              "      <td>58.63692</td>\n",
              "      <td>8.81522</td>\n",
              "      <td>27.28474</td>\n",
              "      <td>5.78046</td>\n",
              "      <td>3.44539</td>\n",
              "      <td>259.10825</td>\n",
              "      <td>10.28525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>41.38639</td>\n",
              "      <td>-20.78665</td>\n",
              "      <td>51.80155</td>\n",
              "      <td>17.21415</td>\n",
              "      <td>-36.44189</td>\n",
              "      <td>-11.53169</td>\n",
              "      <td>11.75252</td>\n",
              "      <td>-7.62428</td>\n",
              "      <td>-3.65488</td>\n",
              "      <td>...</td>\n",
              "      <td>50.37614</td>\n",
              "      <td>-40.48205</td>\n",
              "      <td>48.07805</td>\n",
              "      <td>-7.62399</td>\n",
              "      <td>6.51934</td>\n",
              "      <td>-30.46090</td>\n",
              "      <td>-53.87264</td>\n",
              "      <td>4.44627</td>\n",
              "      <td>58.16913</td>\n",
              "      <td>-0.02409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>37.45034</td>\n",
              "      <td>11.42615</td>\n",
              "      <td>56.28982</td>\n",
              "      <td>19.58426</td>\n",
              "      <td>-16.43530</td>\n",
              "      <td>2.22457</td>\n",
              "      <td>1.02668</td>\n",
              "      <td>-7.34736</td>\n",
              "      <td>-0.01184</td>\n",
              "      <td>...</td>\n",
              "      <td>-22.46207</td>\n",
              "      <td>-25.77228</td>\n",
              "      <td>-322.42841</td>\n",
              "      <td>-146.57408</td>\n",
              "      <td>13.61588</td>\n",
              "      <td>92.22918</td>\n",
              "      <td>-439.80259</td>\n",
              "      <td>25.73235</td>\n",
              "      <td>157.22967</td>\n",
              "      <td>38.70617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>39.71092</td>\n",
              "      <td>-4.92800</td>\n",
              "      <td>12.88590</td>\n",
              "      <td>-11.87773</td>\n",
              "      <td>2.48031</td>\n",
              "      <td>-16.11028</td>\n",
              "      <td>-16.40421</td>\n",
              "      <td>-8.29657</td>\n",
              "      <td>9.86817</td>\n",
              "      <td>...</td>\n",
              "      <td>11.92816</td>\n",
              "      <td>-73.72412</td>\n",
              "      <td>16.19039</td>\n",
              "      <td>9.79606</td>\n",
              "      <td>9.71693</td>\n",
              "      <td>-9.90907</td>\n",
              "      <td>-20.65851</td>\n",
              "      <td>2.34002</td>\n",
              "      <td>-31.57015</td>\n",
              "      <td>1.58400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows × 91 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f4864a8-eda9-4b40-8017-51d4d424818d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f4864a8-eda9-4b40-8017-51d4d424818d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f4864a8-eda9-4b40-8017-51d4d424818d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncjxI4WdzGrA"
      },
      "source": [
        "### Part (a) -- 7%\n",
        "\n",
        "The data set description text asks us to respect the below train/test split to\n",
        "avoid the \"producer effect\". That is, we want to make sure that no song from a single artist\n",
        "ends up in both the training and test set.\n",
        "\n",
        "Explain why it would be problematic to have\n",
        "some songs from an artist in the training set, and other songs from the same artist in the\n",
        "test set. (Hint: Remember that we want our test accuracy to predict how well the model\n",
        "will perform in practice on a song it hasn't learned about.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NiYlxpFzGrB"
      },
      "source": [
        "df_train = df[:463715]\n",
        "df_test = df[463715:]\n",
        "\n",
        "# convert to numpy\n",
        "train_xs = df_train[x_labels].to_numpy()\n",
        "train_ts = df_train[t_label].to_numpy()\n",
        "test_xs = df_test[x_labels].to_numpy()\n",
        "test_ts = df_test[t_label].to_numpy()\n",
        "\n",
        "# Explanation:\n",
        "# Since most of the songs of an artist were written in the same century, it could be argued that splitting a single artist's song into both \n",
        "# training and testing might lead to an over-confident result as the model might recognize the artist and immidietly classify the song into the dominant century\n",
        "# of the artist. The result is that song's century being classified accorsing on the artist."
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYSzd4XUzGrB"
      },
      "source": [
        "### Part (b) -- 7%\n",
        "\n",
        "It can be beneficial to **normalize** the columns, so that each column (feature)\n",
        "has the *same* mean and standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPuWLksJzGrB"
      },
      "source": [
        "feature_means = df_train.mean()[1:].to_numpy() # the [1:] removes the mean of the \"year\" field\n",
        "feature_stds  = df_train.std()[1:].to_numpy()\n",
        "\n",
        "train_norm_xs = (train_xs - feature_means) / feature_stds\n",
        "test_norm_xs = (test_xs - feature_means) / feature_stds"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4zmZk6ezGrC"
      },
      "source": [
        "Notice how in our code, we normalized the test set using the *training data means and standard deviations*.\n",
        "This is *not* a bug.\n",
        "\n",
        "Explain why it would be improper to compute and use test set means\n",
        "and standard deviations. (Hint: Remember what we want to use the test accuracy to measure.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxZy6brwzGrC"
      },
      "source": [
        "# Explanation:\n",
        "# The splitting between training and testing is \"artificial\" - the testing is supposed to represent the model's performence on new unknown data.\n",
        "# Thus, the only \"known\" parameters are the training parameters - the testing parameters are pretented to be hidden. "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4GqL5J_zGrC"
      },
      "source": [
        "### Part (c) -- 7%\n",
        "\n",
        "Finally, we'll move some of the data in our training set into a validation set.\n",
        "\n",
        "Explain why we should limit how many times we use the test set, and that we should use the validation\n",
        "set during the model building process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsXv1U3gzGrC"
      },
      "source": [
        "# shuffle the training set\n",
        "reindex = np.random.permutation(len(train_xs))\n",
        "train_xs = train_xs[reindex]\n",
        "train_norm_xs = train_norm_xs[reindex]\n",
        "train_ts = train_ts[reindex]\n",
        "\n",
        "# use the first 50000 elements of `train_xs` as the validation set\n",
        "train_xs, val_xs           = train_xs[50000:], train_xs[:50000]\n",
        "train_norm_xs, val_norm_xs = train_norm_xs[50000:], train_norm_xs[:50000]\n",
        "train_ts, val_ts           = train_ts[50000:], train_ts[:50000]\n",
        "\n",
        "# Explanation:\n",
        "# We should limit how many times we use the test data, as we do not want to model to adjust (fit) according to the test data (because it would not allow us to examine\n",
        "# the accuracy and performance of our model later - when using the test set), but rather only to the training set.\n",
        "# In order to validate a specific model structure (and specifically - the hyperparameters) we take a small portion of the training set - namely the \"validation\" set.\n",
        " "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy4lt445zGrD"
      },
      "source": [
        "## Part 2. Classification (79%)\n",
        "\n",
        "We will first build a *classification* model to perform decade classification.\n",
        "These helper functions are written for you. All other code that you write in this section should be vectorized whenever possible (i.e., avoid unnecessary loops)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6BA_s-kzGrD"
      },
      "source": [
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "def cross_entropy(t, y):\n",
        "  return -t * np.log(y) - (1 - t) * np.log(1 - y)\n",
        "\n",
        "def cost(y, t):\n",
        "  return np.mean(cross_entropy(t, y))\n",
        "\n",
        "def get_accuracy(y, t):\n",
        "  acc = 0\n",
        "  N = 0\n",
        "  for i in range(len(y)):\n",
        "    N += 1\n",
        "    if (y[i] >= 0.5 and t[i] == 1) or (y[i] < 0.5 and t[i] == 0):\n",
        "      acc += 1\n",
        "  return acc / N"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8ZIfooBzGrD"
      },
      "source": [
        "### Part (a) -- 7%\n",
        "\n",
        "Write a function `pred` that computes the prediction `y` based on logistic regression, i.e., a single layer with weights `w` and bias `b`. The output is given by: \n",
        "\\begin{equation}\n",
        "y = \\sigma({\\bf w}^T {\\bf x} + b),\n",
        "\\end{equation}\n",
        "where the value of $y$ is an estimate of the probability that the song is released in the current century, namely ${\\rm year} =1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naY5mT4_zGrD"
      },
      "source": [
        "def pred(w, b, X):\n",
        "  \"\"\"\n",
        "  Returns the prediction `y` of the target based on the weights `w` and scalar bias `b`.\n",
        "\n",
        "  Preconditions: np.shape(w) == (90,)\n",
        "                 type(b) == float\n",
        "                 np.shape(X) = (N, 90) for some N\n",
        "\n",
        "  >>> pred(np.zeros(90), 1, np.ones([2, 90]))\n",
        "  array([0.73105858, 0.73105858]) # It's okay if your output differs in the last decimals\n",
        "  \"\"\"\n",
        "  # Code:\n",
        "  return sigmoid(X @ w +b)\n",
        "\n",
        "# pred(np.zeros(90), 1, np.ones([2, 90]))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxNdmSd3zGrE"
      },
      "source": [
        "### Part (b) -- 7%\n",
        "\n",
        "Write a function `derivative_cost` that computes and returns the gradients \n",
        "$\\frac{\\partial\\mathcal{L}}{\\partial {\\bf w}}$ and\n",
        "$\\frac{\\partial\\mathcal{L}}{\\partial b}$. Here, `X` is the input, `y` is the prediction, and `t` is the true label.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P80bu7qmzGrE"
      },
      "source": [
        "def derivative_cost(X, y, t):\n",
        "  \"\"\"\n",
        "  Returns a tuple containing the gradients dLdw and dLdb.\n",
        "\n",
        "  Precondition: np.shape(X) == (N, 90) for some N\n",
        "                np.shape(y) == (N,)\n",
        "                np.shape(t) == (N,)\n",
        "\n",
        "  Postcondition: np.shape(dLdw) = (90,)\n",
        "           type(dLdb) = float\n",
        "  \"\"\"\n",
        "  # Code:\n",
        "  dLdw = X.T @ (y-t) / (X.shape[0]) \n",
        "  dLdb = np.mean(y - t)\n",
        "  return dLdw , dLdb"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okPRGM3BjKe2"
      },
      "source": [
        "# **Explenation on Gradients**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHfmPVdsg0eX"
      },
      "source": [
        "**Gradients explanation:**\n",
        "\n",
        "In order to calculate the partial derivatives $\\dfrac{\\partial L}{\\partial w}$ and $\\dfrac{\\partial L}{\\partial b}$, we will use the \"Chain-Rule\", as follows:\n",
        "\n",
        "$$\\dfrac{\\partial L}{\\partial w}=\\dfrac{\\partial L}{\\partial y_n}\\cdot \\dfrac{\\partial y_n}{\\partial z_n}\\cdot \\dfrac{\\partial z_n}{\\partial w}$$\n",
        "\n",
        "$$ \\dfrac{\\partial L}{\\partial b}=\\dfrac{\\partial L}{\\partial y_n}\\cdot \\dfrac{\\partial y_n}{\\partial z_n}\\cdot \\dfrac{\\partial z_n}{\\partial b}$$\n",
        "\n",
        "For that purpose, shown below are the functions explicitly, with the corresponding arguments:\n",
        "$$L(y_n)= \\frac{1}{N}\\sum_{n=1}^{N} \\left[-t_n\\cdot log(y_n)-(1-t_n)\\cdot log(1-y_n) \\right]$$\n",
        "$$y_n(z_n)= \\frac{1}{1+e^{-z_n}}$$\n",
        "$$z_n(w)= w^T\\cdot x_n + b$$\n",
        "\n",
        "This allows calculating each derivative separately in the following manner:\n",
        "$$\\dfrac{\\partial L}{\\partial y_n} =\\frac{1}{N}\\sum_{n=1}^{N} \\left[ \\frac{-t_n}{y_n}+\\frac{1-t_n}{1-y_n} \\right] $$\n",
        "\n",
        "$$\\dfrac{\\partial y_n}{\\partial z_n} = -1(1+e^{-z_n})^{-2}\\cdot (-e^{-z_n}) = \\frac{1}{e^{z_n}(1+e^{-z_n})}\\cdot \\frac{1}{1+e^{-z_n}}=(1-y_n)\\cdot y_n $$\n",
        "$$\\dfrac{\\partial z_n}{\\partial w} = x_n $$\n",
        "$$\\dfrac{\\partial z_n}{\\partial b} = 1 $$\n",
        "\n",
        "Plugging these results gives:\n",
        "\n",
        "$$ \\dfrac{\\partial L}{\\partial w}=\\frac{1}{N}\\sum_{n=1}^{N} \\left[(-t_n(1-y_n)+(1-t_n)y_n)\\cdot x_n \\right] = \\frac{1}{N}\\sum_{n=1}^{N} \\left[(y_n-t_n)\\cdot x_n \\right] $$\n",
        "$$ \\dfrac{\\partial L}{\\partial b}=\\frac{1}{N}\\sum_{n=1}^{N} \\left[(-t_n(1-y_n)+(1-t_n)y_n) \\right] = \\frac{1}{N}\\sum_{n=1}^{N} \\left[(y_n-t_n) \\right] $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhQXAKd4zGrE"
      },
      "source": [
        "### Part (c) -- 7%\n",
        "\n",
        "We can check that our derivative is implemented correctly using the finite difference rule. In 1D, the\n",
        "finite difference rule tells us that for small $h$, we should have\n",
        "\n",
        "$$\\frac{f(x+h) - f(x)}{h} \\approx f'(x)$$\n",
        "\n",
        "Show that $\\frac{\\partial\\mathcal{L}}{\\partial b}$  is implement correctly\n",
        "by comparing the result from `derivative_cost` with the empirical cost derivative computed using the above numerical approximation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpRTD-fozGrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c18a008-7c4c-44b0-907e-6b253e469d0e"
      },
      "source": [
        "# Code\n",
        "\n",
        "N = 10\n",
        "h = 1e-5\n",
        "\n",
        "X = train_norm_xs[0:N,:]\n",
        "t = train_ts[0:N,0]\n",
        "w = np.zeros(90)\n",
        "b = 1\n",
        "\n",
        "\n",
        "y_0 = pred (w, b, X)\n",
        "y_1 = pred (w, b+h, X)\n",
        "\n",
        "r1 = (cost(y_1,t)-cost(y_0,t))/h\n",
        "_ , r2 = derivative_cost(X, y_0, t)\n",
        "\n",
        "print(\"The analytical results is -\", r1)\n",
        "print(\"The algorithm results is - \", r2)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The analytical results is - 0.23105956170610395\n",
            "The algorithm results is -  0.23105857863000487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTiplTPhzGrF"
      },
      "source": [
        "### Part (d) -- 7%\n",
        "\n",
        "Show that $\\frac{\\partial\\mathcal{L}}{\\partial {\\bf w}}$  is implement correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVTsHgnPzGrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b146567c-3d53-4785-89df-6a9f9e361e9a"
      },
      "source": [
        "# Code:\n",
        "H = np.zeros(90)\n",
        "r1 = np.zeros(90)\n",
        "\n",
        "for ii in range(w.shape[0]):\n",
        "  H[ii] = h\n",
        "  y_1 = pred (w+H, b, X)\n",
        "  r1_i = (cost(y_1,t)-cost(y_0,t))/h\n",
        "  H[ii] = 0\n",
        "  r1[ii]=r1_i\n",
        "r2 , _ = derivative_cost(X, y_0, t)\n",
        "\n",
        "print(\"The analytical results is -\", r1)\n",
        "print(\"The algorithm results is - \", r2)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The analytical results is - [-0.15646059 -0.01110551 -0.12495073 -0.27464987  0.16531113 -0.13941669\n",
            "  0.12291404  0.08425662 -0.13058024 -0.22855004 -0.2890245  -0.0092107\n",
            "  0.01819065 -0.07816652  0.00267493 -0.10164955  0.02876368 -0.18040205\n",
            " -0.09152012 -0.06946275 -0.18089166 -0.11695674 -0.19144274 -0.06749405\n",
            "  0.06511637  0.08246361  0.0584202  -0.22130431 -0.16343002 -0.0341818\n",
            "  0.10429943 -0.09481999 -0.1157904  -0.07697447  0.05977767  0.13436205\n",
            "  0.080176   -0.1969207  -0.11257826  0.03456533  0.13056949 -0.09670531\n",
            "  0.01493955 -0.00226216 -0.20253976  0.07912124 -0.26552509 -0.12219252\n",
            "  0.07768714 -0.17515613 -0.01697122 -0.06419595 -0.02979651  0.02938538\n",
            " -0.17296063 -0.06839898  0.08266673 -0.05385141 -0.0173734   0.05445124\n",
            " -0.19461781 -0.04198448 -0.02430058 -0.00689626 -0.02696634  0.12835755\n",
            " -0.07987922 -0.15526358 -0.10472275 -0.1559577  -0.00737345 -0.07817276\n",
            " -0.0339723  -0.01201043  0.15461413  0.07095925  0.17205034  0.21426256\n",
            "  0.11142809 -0.05235576 -0.05281814  0.03560195 -0.023689   -0.27005405\n",
            "  0.12568565  0.04437698 -0.3053137   0.04722537  0.03283772 -0.02629777]\n",
            "The algorithm results is -  [-0.15646125 -0.0111063  -0.12495179 -0.27465053  0.16531063 -0.13941756\n",
            "  0.12291357  0.08425572 -0.13058073 -0.22855094 -0.28902594 -0.00921121\n",
            "  0.01819019 -0.07816688  0.00267464 -0.10165013  0.0287633  -0.18040262\n",
            " -0.09152057 -0.06946372 -0.18089207 -0.1169575  -0.19144353 -0.0674942\n",
            "  0.06511616  0.0824632   0.05841989 -0.22130516 -0.16343056 -0.03418202\n",
            "  0.1042992  -0.0948218  -0.1157911  -0.07697466  0.05977755  0.13436146\n",
            "  0.08017533 -0.19692107 -0.1125794   0.03456506  0.130569   -0.09670551\n",
            "  0.01493891 -0.0022628  -0.20254036  0.07912091 -0.26552559 -0.12219309\n",
            "  0.07768705 -0.17515695 -0.01697134 -0.06419607 -0.02979738  0.02938532\n",
            " -0.17296133 -0.06839928  0.08266633 -0.05385202 -0.01737383  0.05445081\n",
            " -0.19461859 -0.04198488 -0.02430109 -0.00689692 -0.02696799  0.12835734\n",
            " -0.07987983 -0.15526375 -0.10472324 -0.15595853 -0.00737375 -0.07817294\n",
            " -0.03397249 -0.01201071  0.15461357  0.07095839  0.17205001  0.21426182\n",
            "  0.11142749 -0.05235668 -0.0528188   0.03560173 -0.02368964 -0.27005453\n",
            "  0.125685    0.04437668 -0.30531444  0.04722437  0.03283741 -0.02629823]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgBTPF_2zGrG"
      },
      "source": [
        "### Part (e) -- 7%\n",
        "\n",
        "Now that you have a gradient function that works, we can actually run gradient descent. \n",
        "Complete the following code that will run stochastic: gradient descent training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW4DEuuPzGrG"
      },
      "source": [
        "def run_gradient_descent(train_norm_xs, train_ts, val_norm_xs, val_ts, w0, b0, mu=0.1, batch_size=100, max_iters=100):\n",
        "  \"\"\"Return the values of (w, b) after running gradient descent for max_iters.\n",
        "  We use:\n",
        "    - train_norm_xs and train_ts as the training set\n",
        "    - val_norm_xs and val_ts as the test set\n",
        "    - mu as the learning rate\n",
        "    - (w0, b0) as the initial values of (w, b)\n",
        "\n",
        "  Precondition: np.shape(w0) == (90,)\n",
        "                type(b0) == float\n",
        " \n",
        "  Postcondition: np.shape(w) == (90,)\n",
        "                 type(b) == float\n",
        "  \"\"\"\n",
        "  w = w0\n",
        "  b = b0\n",
        "  iter = 0\n",
        "  val_log = {'accuracy': [], 'cost': []}\n",
        "\n",
        "  while iter < max_iters:\n",
        "\n",
        "    # shuffle the training set:\n",
        "    reindex = np.random.permutation(len(train_norm_xs))\n",
        "    train_norm_xs = train_norm_xs[reindex]\n",
        "    train_ts = train_ts[reindex]\n",
        "\n",
        "    for i in range(0, len(train_norm_xs), batch_size): # iterate over each minibatch\n",
        "      # minibatch that we are working with:\n",
        "      X = train_norm_xs[i:(i + batch_size)]\n",
        "      t = train_ts[i:(i + batch_size), 0]\n",
        "\n",
        "      # since len(train_norm_xs) does not divide batch_size evenly, we will skip over\n",
        "      # the \"last\" minibatch\n",
        "      if np.shape(X)[0] != batch_size:\n",
        "        continue\n",
        "      \n",
        "      # compute the prediction\n",
        "      y = pred (w, b, X)\n",
        "\n",
        "      # update w and b\n",
        "      dLdw , dLdb = derivative_cost(X, y, t)\n",
        "      w -= mu * dLdw\n",
        "      b -= mu * dLdb\n",
        "\n",
        "    # increment the iteration count\n",
        "    iter += 1\n",
        "    # compute and print the *validation* loss and accuracy\n",
        "    if (iter % 10 == 0):\n",
        "      val_y = pred(w,b,val_norm_xs)\n",
        "      val_cost = cost(val_y,val_ts)\n",
        "      val_acc = get_accuracy(val_y, val_ts)\n",
        "      print(\"Iter %d. [Val Acc %.0f%%, Loss %f]\" % (\n",
        "              iter, val_acc * 100, val_cost))\n",
        "      # Log validation data\n",
        "      val_log[\"accuracy\"].append(val_acc)\n",
        "      val_log[\"cost\"].append(val_cost)\n",
        "\n",
        "      if iter >= max_iters:\n",
        "        break\n",
        "\n",
        "      # Think what parameters you should return for further use\n",
        "      \n",
        "  return val_log, w, b\n",
        "  \n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MqzT0jGzGrH"
      },
      "source": [
        "### Part (f) -- 7%\n",
        "\n",
        "Call `run_gradient_descent` with the weights and biases all initialized to zero.\n",
        "Show that if the learning rate $\\mu$ is too small, then convergence is slow.\n",
        "Also, show that if $\\mu$ is too large, then the optimization algorirthm does not converge. The demonstration should be made using plots showing these effects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE32Iqo6zGrH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3aa59b75-af46-4253-b4d7-c298f59684f8"
      },
      "source": [
        "# Code:\n",
        "w0 = np.zeros(90)\n",
        "b0 = np.zeros(1)[0]\n",
        "\n",
        "w0 = np.random.randn(90)\n",
        "b0 = np.random.randn(1)[0]\n",
        "\n",
        "mu_vec = [1e-2, 1e-1, 2]\n",
        "fig, ax = plt.subplots(1,2, figsize=(10, 5))\n",
        "iter=300;\n",
        "\n",
        "for mu in mu_vec:\n",
        "  print('mu = ',mu)\n",
        "  log, _ , _ = run_gradient_descent(train_norm_xs[:100000], train_ts[:100000], val_norm_xs[:5000],val_ts[:5000], w0, b0, mu, batch_size=1500, max_iters=iter)\n",
        "  # log, _, _ = run_gradient_descent(train_norm_xs, train_ts, val_norm_xs[:1000],val_ts[:1000], w0, b0, mu, batch_size=100, max_iters=iter)\n",
        "  ax[0].plot(np.arange(0,iter,10),log[\"accuracy\"][:],label = \"mu = \"+str(mu))\n",
        "  ax[1].plot(np.arange(0,iter,10),log[\"cost\"][:],label = \"mu = \"+str(mu))\n",
        "\n",
        "ax[0].set_xlabel('# Iteration')\n",
        "ax[0].set_ylabel('[%]')\n",
        "ax[1].set_xlabel('# Iteration')\n",
        "ax[0].set_title('Accuracy')\n",
        "ax[1].set_title('Loss')\n",
        "ax[1].legend(loc='center left')\n",
        "ax[0].grid()\n",
        "ax[1].grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mu =  0.01\n",
            "Iter 10. [Val Acc 55%, Loss 1.911888]\n",
            "Iter 20. [Val Acc 60%, Loss 1.470987]\n",
            "Iter 30. [Val Acc 64%, Loss 1.219457]\n",
            "Iter 40. [Val Acc 67%, Loss 1.073671]\n",
            "Iter 50. [Val Acc 68%, Loss 0.991498]\n",
            "Iter 60. [Val Acc 70%, Loss 0.944149]\n",
            "Iter 70. [Val Acc 70%, Loss 0.915822]\n",
            "Iter 80. [Val Acc 71%, Loss 0.898247]\n",
            "Iter 90. [Val Acc 72%, Loss 0.886835]\n",
            "Iter 100. [Val Acc 72%, Loss 0.879315]\n",
            "Iter 110. [Val Acc 72%, Loss 0.873931]\n",
            "Iter 120. [Val Acc 73%, Loss 0.870323]\n",
            "Iter 130. [Val Acc 73%, Loss 0.867899]\n",
            "Iter 140. [Val Acc 73%, Loss 0.866211]\n",
            "Iter 150. [Val Acc 73%, Loss 0.864614]\n",
            "Iter 160. [Val Acc 73%, Loss 0.863493]\n",
            "Iter 170. [Val Acc 73%, Loss 0.862915]\n",
            "Iter 180. [Val Acc 73%, Loss 0.862442]\n",
            "Iter 190. [Val Acc 73%, Loss 0.861922]\n",
            "Iter 200. [Val Acc 73%, Loss 0.861877]\n",
            "Iter 210. [Val Acc 73%, Loss 0.861662]\n",
            "Iter 220. [Val Acc 73%, Loss 0.861794]\n",
            "Iter 230. [Val Acc 73%, Loss 0.861511]\n",
            "Iter 240. [Val Acc 73%, Loss 0.861496]\n",
            "Iter 250. [Val Acc 73%, Loss 0.861590]\n",
            "Iter 260. [Val Acc 73%, Loss 0.861472]\n",
            "Iter 270. [Val Acc 73%, Loss 0.861570]\n",
            "Iter 280. [Val Acc 73%, Loss 0.861481]\n",
            "Iter 290. [Val Acc 73%, Loss 0.861613]\n",
            "Iter 300. [Val Acc 73%, Loss 0.861650]\n",
            "mu =  0.1\n",
            "Iter 10. [Val Acc 73%, Loss 0.860833]\n",
            "Iter 20. [Val Acc 73%, Loss 0.861175]\n",
            "Iter 30. [Val Acc 73%, Loss 0.863883]\n",
            "Iter 40. [Val Acc 73%, Loss 0.862001]\n",
            "Iter 50. [Val Acc 73%, Loss 0.861854]\n",
            "Iter 60. [Val Acc 73%, Loss 0.862406]\n",
            "Iter 70. [Val Acc 73%, Loss 0.863297]\n",
            "Iter 80. [Val Acc 73%, Loss 0.862584]\n",
            "Iter 90. [Val Acc 73%, Loss 0.862585]\n",
            "Iter 100. [Val Acc 73%, Loss 0.862808]\n",
            "Iter 110. [Val Acc 73%, Loss 0.862463]\n",
            "Iter 120. [Val Acc 73%, Loss 0.861876]\n",
            "Iter 130. [Val Acc 73%, Loss 0.863149]\n",
            "Iter 140. [Val Acc 73%, Loss 0.864638]\n",
            "Iter 150. [Val Acc 73%, Loss 0.861832]\n",
            "Iter 160. [Val Acc 73%, Loss 0.861077]\n",
            "Iter 170. [Val Acc 73%, Loss 0.861531]\n",
            "Iter 180. [Val Acc 73%, Loss 0.862899]\n",
            "Iter 190. [Val Acc 73%, Loss 0.862405]\n",
            "Iter 200. [Val Acc 73%, Loss 0.862010]\n",
            "Iter 210. [Val Acc 73%, Loss 0.863029]\n",
            "Iter 220. [Val Acc 73%, Loss 0.862509]\n",
            "Iter 230. [Val Acc 73%, Loss 0.862734]\n",
            "Iter 240. [Val Acc 73%, Loss 0.863005]\n",
            "Iter 250. [Val Acc 73%, Loss 0.861699]\n",
            "Iter 260. [Val Acc 73%, Loss 0.862327]\n",
            "Iter 270. [Val Acc 73%, Loss 0.862017]\n",
            "Iter 280. [Val Acc 73%, Loss 0.862527]\n",
            "Iter 290. [Val Acc 73%, Loss 0.865034]\n",
            "Iter 300. [Val Acc 73%, Loss 0.861897]\n",
            "mu =  2\n",
            "Iter 10. [Val Acc 65%, Loss 1.313864]\n",
            "Iter 20. [Val Acc 66%, Loss 1.304199]\n",
            "Iter 30. [Val Acc 66%, Loss 1.335861]\n",
            "Iter 40. [Val Acc 65%, Loss 1.402621]\n",
            "Iter 50. [Val Acc 68%, Loss 1.266521]\n",
            "Iter 60. [Val Acc 67%, Loss 1.379858]\n",
            "Iter 70. [Val Acc 65%, Loss 1.405809]\n",
            "Iter 80. [Val Acc 66%, Loss 1.300496]\n",
            "Iter 90. [Val Acc 65%, Loss 1.319113]\n",
            "Iter 100. [Val Acc 67%, Loss 1.348840]\n",
            "Iter 110. [Val Acc 66%, Loss 1.277818]\n",
            "Iter 120. [Val Acc 68%, Loss 1.267455]\n",
            "Iter 130. [Val Acc 67%, Loss 1.306457]\n",
            "Iter 140. [Val Acc 67%, Loss 1.288347]\n",
            "Iter 150. [Val Acc 68%, Loss 1.265162]\n",
            "Iter 160. [Val Acc 66%, Loss 1.365759]\n",
            "Iter 170. [Val Acc 65%, Loss 1.327563]\n",
            "Iter 180. [Val Acc 67%, Loss 1.283292]\n",
            "Iter 190. [Val Acc 69%, Loss 1.166466]\n",
            "Iter 200. [Val Acc 68%, Loss 1.278329]\n",
            "Iter 210. [Val Acc 66%, Loss 1.417172]\n",
            "Iter 220. [Val Acc 69%, Loss 1.217302]\n",
            "Iter 230. [Val Acc 65%, Loss 1.414744]\n",
            "Iter 240. [Val Acc 66%, Loss 1.342355]\n",
            "Iter 250. [Val Acc 66%, Loss 1.409509]\n",
            "Iter 260. [Val Acc 66%, Loss 1.335502]\n",
            "Iter 270. [Val Acc 66%, Loss 1.334660]\n",
            "Iter 280. [Val Acc 68%, Loss 1.272699]\n",
            "Iter 290. [Val Acc 68%, Loss 1.337957]\n",
            "Iter 300. [Val Acc 64%, Loss 1.464720]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S44GmUZ12o-g"
      },
      "source": [
        "**Explain and discuss your results here:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ5HlDFAzGrH"
      },
      "source": [
        "### Part (g) -- 7%\n",
        "\n",
        "Find the optimial value of ${\\bf w}$ and $b$ using your code. Explain how you chose\n",
        "the learning rate $\\mu$ and the batch size. Show plots demostrating good and bad behaviours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dFOFSwgzGrI"
      },
      "source": [
        "w0 = np.random.randn(90)\n",
        "b0 = np.random.randn(1)[0]\n",
        "\n",
        "# Write your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkZt7_932zX2"
      },
      "source": [
        "**Explain and discuss your results here:**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KrQqSj2zGrI"
      },
      "source": [
        "### Part (h) -- 15%\n",
        "\n",
        "Using the values of `w` and `b` from part (g), compute your training accuracy, validation accuracy,\n",
        "and test accuracy. Are there any differences between those three values? If so, why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuKw2mLozGrI"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "train_acc = ...\n",
        "val_acc = ...\n",
        "test_acc = ...\n",
        "\n",
        "print('train_acc = ', train_acc, ' val_acc = ', val_acc, ' test_acc = ', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXZa1u6920M3"
      },
      "source": [
        "**Explain and discuss your results here:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4eP2Yh1zGrI"
      },
      "source": [
        "### Part (i) -- 15%\n",
        "\n",
        "Writing a classifier like this is instructive, and helps you understand what happens when\n",
        "we train a model. However, in practice, we rarely write model building and training code\n",
        "from scratch. Instead, we typically use one of the well-tested libraries available in a package.\n",
        "\n",
        "Use `sklearn.linear_model.LogisticRegression` to build a linear classifier, and make predictions about the test set. Start by reading the\n",
        "[API documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
        "\n",
        "Compute the training, validation and test accuracy of this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24LCfAa1zGrJ"
      },
      "source": [
        "import sklearn.linear_model\n",
        "\n",
        "model = ...\n",
        "\n",
        "train_acc = ...\n",
        "val_acc = ...\n",
        "test_acc = ...\n",
        "\n",
        "print('train_acc = ', train_acc, ' val_acc = ', val_acc, ' test_acc = ', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRqucdV923tG"
      },
      "source": [
        "**This parts helps by checking if the code worked.**\n",
        "**Check if you get similar results, if not repair your code**\n"
      ]
    }
  ]
}