{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yonatandn/IDL/blob/develop/Assignment1_group58.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bhfIKbQzGq2"
      },
      "source": [
        "# Assignment 1. Music Century Classification\n",
        "\n",
        "**Assignment Responsible**: Natalie Lang.\n",
        "Te\n",
        "In this assignment, we will build models to predict which\n",
        "**century** a piece of music was released.  We will be using the \"YearPredictionMSD Data Set\"\n",
        "based on the Million Song Dataset. The data is available to download from the UCI \n",
        "Machine Learning Repository. Here are some links about the data:\n",
        "\n",
        "- https://archive.ics.uci.edu/ml/datasets/yearpredictionmsd\n",
        "- http://millionsongdataset.com/pages/tasks-demos/#yearrecognition\n",
        "\n",
        "Note that you are note allowed to import additional packages **(especially not PyTorch)**. One of the objectives is to understand how the training procedure actually operates, before working with PyTorch's autograd engine which does it all for us.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47oq1vy5PUIV"
      },
      "source": [
        "## Question 1. Data (21%)\n",
        "\n",
        "Start by setting up a Google Colab notebook in which to do your work.\n",
        "Since you are working with a partner, you might find this link helpful:\n",
        "\n",
        "- https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb\n",
        "\n",
        "The recommended way to work together is pair coding, where you and your partner are sitting together and writing code together. \n",
        "\n",
        "To process and read the data, we use the popular `pandas` package for data analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aFWpuNSzGq9"
      },
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7UWL6mFzGq-"
      },
      "source": [
        "Now that your notebook is set up, we can load the data into the notebook. The code below provides\n",
        "two ways of loading the data: directly from the internet, or through mounting Google Drive.\n",
        "The first method is easier but slower, and the second method is a bit involved at first, but\n",
        "can save you time later on. You will need to mount Google Drive for later assignments, so we recommend\n",
        "figuring how to do that now.\n",
        "\n",
        "Here are some resources to help you get started:\n",
        "\n",
        "- http.://colab.research.google.com/notebooks/io.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY6PrfV4zGq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb0347e-dbe3-484e-b419-f5eaa7b9b64c"
      },
      "source": [
        "load_from_drive = True\n",
        "\n",
        "if not load_from_drive:\n",
        "  csv_path = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\"\n",
        "else:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  csv_path = '/content/gdrive/MyDrive/IDL_Data/YearPredictionMSD.txt.zip' \n",
        "\n",
        "t_label = [\"year\"]\n",
        "x_labels = [\"var%d\" % i for i in range(1, 91)]\n",
        "df = pandas.read_csv(csv_path, names=t_label + x_labels)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgB83beNzGq_"
      },
      "source": [
        "Now that the data is loaded to your Colab notebook, you should be able to display the Pandas\n",
        "DataFrame `df` as a table:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5bBEnj3zGq_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "737daf70-cd53-4694-d8ac-093d5421f157"
      },
      "source": [
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        year      var1      var2      var3      var4      var5      var6  \\\n",
              "0       2001  49.94357  21.47114  73.07750   8.74861 -17.40628 -13.09905   \n",
              "1       2001  48.73215  18.42930  70.32679  12.94636 -10.32437 -24.83777   \n",
              "2       2001  50.95714  31.85602  55.81851  13.41693  -6.57898 -18.54940   \n",
              "3       2001  48.24750  -1.89837  36.29772   2.58776   0.97170 -26.21683   \n",
              "4       2001  50.97020  42.20998  67.09964   8.46791 -15.85279 -16.81409   \n",
              "...      ...       ...       ...       ...       ...       ...       ...   \n",
              "515340  2006  51.28467  45.88068  22.19582  -5.53319  -3.61835 -16.36914   \n",
              "515341  2006  49.87870  37.93125  18.65987  -3.63581 -27.75665 -18.52988   \n",
              "515342  2006  45.12852  12.65758 -38.72018   8.80882 -29.29985  -2.28706   \n",
              "515343  2006  44.16614  32.38368  -3.34971  -2.49165 -19.59278 -18.67098   \n",
              "515344  2005  51.85726  59.11655  26.39436  -5.46030 -20.69012 -19.95528   \n",
              "\n",
              "            var7      var8      var9  ...     var81      var82      var83  \\\n",
              "0      -25.01202 -12.23257   7.83089  ...  13.01620  -54.40548   58.99367   \n",
              "1        8.76630  -0.92019  18.76548  ...   5.66812  -19.68073   33.04964   \n",
              "2       -3.27872  -2.35035  16.07017  ...   3.03800   26.05866  -50.92779   \n",
              "3        5.05097 -10.34124   3.55005  ...  34.57337 -171.70734  -16.96705   \n",
              "4      -12.48207  -9.37636  12.63699  ...   9.92661  -55.95724   64.92712   \n",
              "...          ...       ...       ...  ...       ...        ...        ...   \n",
              "515340   2.12652   5.18160  -8.66890  ...   4.81440   -3.75991  -30.92584   \n",
              "515341   7.76108   3.56109  -2.50351  ...  32.38589  -32.75535  -61.05473   \n",
              "515342 -18.40424 -22.28726  -4.52429  ... -18.73598  -71.15954 -123.98443   \n",
              "515343   8.78428   4.02039 -12.01230  ...  67.16763  282.77624   -4.63677   \n",
              "515344  -6.72771   2.29590  10.31018  ... -11.50511  -69.18291   60.58456   \n",
              "\n",
              "            var84     var85     var86      var87     var88      var89  \\\n",
              "0        15.37344   1.11144 -23.08793   68.40795  -1.82223  -27.46348   \n",
              "1        42.87836  -9.90378 -32.22788   70.49388  12.04941   58.43453   \n",
              "2        10.93792  -0.07568  43.20130 -115.00698  -0.05859   39.67068   \n",
              "3       -46.67617 -12.51516  82.58061  -72.08993   9.90558  199.62971   \n",
              "4       -17.72522  -1.49237  -7.50035   51.76631   7.88713   55.66926   \n",
              "...           ...       ...       ...        ...       ...        ...   \n",
              "515340   26.33968  -5.03390  21.86037 -142.29410   3.42901  -41.14721   \n",
              "515341   56.65182  15.29965  95.88193  -10.63242  12.96552   92.11633   \n",
              "515342  121.26989  10.89629  34.62409 -248.61020  -6.07171   53.96319   \n",
              "515343  144.00125  21.62652 -29.72432   71.47198  20.32240   14.83107   \n",
              "515344   28.64599  -4.39620 -64.56491  -45.61012  -5.51512   32.35602   \n",
              "\n",
              "           var90  \n",
              "0        2.26327  \n",
              "1       26.92061  \n",
              "2       -0.66345  \n",
              "3       18.85382  \n",
              "4       28.74903  \n",
              "...          ...  \n",
              "515340 -15.46052  \n",
              "515341  10.88815  \n",
              "515342  -8.09364  \n",
              "515343  39.74909  \n",
              "515344  12.17352  \n",
              "\n",
              "[515345 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-156bd3f1-733a-4151-9c55-0844af19d736\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>var3</th>\n",
              "      <th>var4</th>\n",
              "      <th>var5</th>\n",
              "      <th>var6</th>\n",
              "      <th>var7</th>\n",
              "      <th>var8</th>\n",
              "      <th>var9</th>\n",
              "      <th>...</th>\n",
              "      <th>var81</th>\n",
              "      <th>var82</th>\n",
              "      <th>var83</th>\n",
              "      <th>var84</th>\n",
              "      <th>var85</th>\n",
              "      <th>var86</th>\n",
              "      <th>var87</th>\n",
              "      <th>var88</th>\n",
              "      <th>var89</th>\n",
              "      <th>var90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515340</th>\n",
              "      <td>2006</td>\n",
              "      <td>51.28467</td>\n",
              "      <td>45.88068</td>\n",
              "      <td>22.19582</td>\n",
              "      <td>-5.53319</td>\n",
              "      <td>-3.61835</td>\n",
              "      <td>-16.36914</td>\n",
              "      <td>2.12652</td>\n",
              "      <td>5.18160</td>\n",
              "      <td>-8.66890</td>\n",
              "      <td>...</td>\n",
              "      <td>4.81440</td>\n",
              "      <td>-3.75991</td>\n",
              "      <td>-30.92584</td>\n",
              "      <td>26.33968</td>\n",
              "      <td>-5.03390</td>\n",
              "      <td>21.86037</td>\n",
              "      <td>-142.29410</td>\n",
              "      <td>3.42901</td>\n",
              "      <td>-41.14721</td>\n",
              "      <td>-15.46052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515341</th>\n",
              "      <td>2006</td>\n",
              "      <td>49.87870</td>\n",
              "      <td>37.93125</td>\n",
              "      <td>18.65987</td>\n",
              "      <td>-3.63581</td>\n",
              "      <td>-27.75665</td>\n",
              "      <td>-18.52988</td>\n",
              "      <td>7.76108</td>\n",
              "      <td>3.56109</td>\n",
              "      <td>-2.50351</td>\n",
              "      <td>...</td>\n",
              "      <td>32.38589</td>\n",
              "      <td>-32.75535</td>\n",
              "      <td>-61.05473</td>\n",
              "      <td>56.65182</td>\n",
              "      <td>15.29965</td>\n",
              "      <td>95.88193</td>\n",
              "      <td>-10.63242</td>\n",
              "      <td>12.96552</td>\n",
              "      <td>92.11633</td>\n",
              "      <td>10.88815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515342</th>\n",
              "      <td>2006</td>\n",
              "      <td>45.12852</td>\n",
              "      <td>12.65758</td>\n",
              "      <td>-38.72018</td>\n",
              "      <td>8.80882</td>\n",
              "      <td>-29.29985</td>\n",
              "      <td>-2.28706</td>\n",
              "      <td>-18.40424</td>\n",
              "      <td>-22.28726</td>\n",
              "      <td>-4.52429</td>\n",
              "      <td>...</td>\n",
              "      <td>-18.73598</td>\n",
              "      <td>-71.15954</td>\n",
              "      <td>-123.98443</td>\n",
              "      <td>121.26989</td>\n",
              "      <td>10.89629</td>\n",
              "      <td>34.62409</td>\n",
              "      <td>-248.61020</td>\n",
              "      <td>-6.07171</td>\n",
              "      <td>53.96319</td>\n",
              "      <td>-8.09364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515343</th>\n",
              "      <td>2006</td>\n",
              "      <td>44.16614</td>\n",
              "      <td>32.38368</td>\n",
              "      <td>-3.34971</td>\n",
              "      <td>-2.49165</td>\n",
              "      <td>-19.59278</td>\n",
              "      <td>-18.67098</td>\n",
              "      <td>8.78428</td>\n",
              "      <td>4.02039</td>\n",
              "      <td>-12.01230</td>\n",
              "      <td>...</td>\n",
              "      <td>67.16763</td>\n",
              "      <td>282.77624</td>\n",
              "      <td>-4.63677</td>\n",
              "      <td>144.00125</td>\n",
              "      <td>21.62652</td>\n",
              "      <td>-29.72432</td>\n",
              "      <td>71.47198</td>\n",
              "      <td>20.32240</td>\n",
              "      <td>14.83107</td>\n",
              "      <td>39.74909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515344</th>\n",
              "      <td>2005</td>\n",
              "      <td>51.85726</td>\n",
              "      <td>59.11655</td>\n",
              "      <td>26.39436</td>\n",
              "      <td>-5.46030</td>\n",
              "      <td>-20.69012</td>\n",
              "      <td>-19.95528</td>\n",
              "      <td>-6.72771</td>\n",
              "      <td>2.29590</td>\n",
              "      <td>10.31018</td>\n",
              "      <td>...</td>\n",
              "      <td>-11.50511</td>\n",
              "      <td>-69.18291</td>\n",
              "      <td>60.58456</td>\n",
              "      <td>28.64599</td>\n",
              "      <td>-4.39620</td>\n",
              "      <td>-64.56491</td>\n",
              "      <td>-45.61012</td>\n",
              "      <td>-5.51512</td>\n",
              "      <td>32.35602</td>\n",
              "      <td>12.17352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>515345 rows Ã— 91 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-156bd3f1-733a-4151-9c55-0844af19d736')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-156bd3f1-733a-4151-9c55-0844af19d736 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-156bd3f1-733a-4151-9c55-0844af19d736');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaLuAMH_zGrA"
      },
      "source": [
        "To set up our data for classification, we'll use the \"year\" field to represent\n",
        "whether a song was released in the 20-th century. In our case `df[\"year\"]` will be 1 if\n",
        "the year was released after 2000, and 0 otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZdGlNgdzGrA"
      },
      "source": [
        "df[\"year\"] = df[\"year\"].map(lambda x: int(x > 2000))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xugy7FZ8eoAd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "outputId": "cf26195a-133b-412f-8aa0-daebac20f61b"
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    year      var1       var2      var3      var4      var5      var6  \\\n",
              "0      1  49.94357   21.47114  73.07750   8.74861 -17.40628 -13.09905   \n",
              "1      1  48.73215   18.42930  70.32679  12.94636 -10.32437 -24.83777   \n",
              "2      1  50.95714   31.85602  55.81851  13.41693  -6.57898 -18.54940   \n",
              "3      1  48.24750   -1.89837  36.29772   2.58776   0.97170 -26.21683   \n",
              "4      1  50.97020   42.20998  67.09964   8.46791 -15.85279 -16.81409   \n",
              "5      1  50.54767    0.31568  92.35066  22.38696 -25.51870 -19.04928   \n",
              "6      1  50.57546   33.17843  50.53517  11.55217 -27.24764  -8.78206   \n",
              "7      1  48.26892    8.97526  75.23158  24.04945 -16.02105 -14.09491   \n",
              "8      1  49.75468   33.99581  56.73846   2.89581  -2.92429 -26.44413   \n",
              "9      1  45.17809   46.34234 -40.65357  -2.47909   1.21253  -0.65302   \n",
              "10     1  39.13076  -23.01763 -36.20583   1.67519  -4.27101  13.01158   \n",
              "11     1  37.66498  -34.05910 -17.36060 -26.77781 -39.95119 -20.75000   \n",
              "12     1  26.51957 -148.15762 -13.30095  -7.25851  17.22029 -21.99439   \n",
              "13     1  37.68491  -26.84185 -27.10566 -14.95883  -5.87200 -21.68979   \n",
              "14     0  39.11695   -8.29767 -51.37966  -4.42668 -30.06506 -11.95916   \n",
              "15     1  35.05129  -67.97714 -14.20239  -6.68696  -0.61230 -18.70341   \n",
              "16     1  33.63129  -96.14912 -89.38216 -12.11699  13.77252  -6.69377   \n",
              "17     0  41.38639  -20.78665  51.80155  17.21415 -36.44189 -11.53169   \n",
              "18     0  37.45034   11.42615  56.28982  19.58426 -16.43530   2.22457   \n",
              "19     0  39.71092   -4.92800  12.88590 -11.87773   2.48031 -16.11028   \n",
              "\n",
              "        var7      var8      var9  ...     var81      var82      var83  \\\n",
              "0  -25.01202 -12.23257   7.83089  ...  13.01620  -54.40548   58.99367   \n",
              "1    8.76630  -0.92019  18.76548  ...   5.66812  -19.68073   33.04964   \n",
              "2   -3.27872  -2.35035  16.07017  ...   3.03800   26.05866  -50.92779   \n",
              "3    5.05097 -10.34124   3.55005  ...  34.57337 -171.70734  -16.96705   \n",
              "4  -12.48207  -9.37636  12.63699  ...   9.92661  -55.95724   64.92712   \n",
              "5   20.67345  -5.19943   3.63566  ...   6.59753  -50.69577   26.02574   \n",
              "6  -12.04282  -9.53930  28.61811  ...  11.63681   25.44182  134.62382   \n",
              "7    8.11871  -1.87566   7.46701  ...  18.03989  -58.46192  -65.56438   \n",
              "8    1.71392  -0.55644  22.08594  ...  18.70812    5.20391  -27.75192   \n",
              "9   -6.95536 -12.20040  17.02512  ...  -4.36742  -87.55285  -70.79677   \n",
              "10   8.05718  -8.41088   6.27370  ...  32.86051  -26.08461 -186.82429   \n",
              "11  -0.10231  -0.89972  -1.30205  ...  11.18909   45.20614   53.83925   \n",
              "12   5.51947   3.48418   2.61738  ...  23.80442  251.76360   18.81642   \n",
              "13   4.87374 -18.01800   1.52141  ... -67.57637  234.27192  -72.34557   \n",
              "14  -0.85322  -8.86179  11.36680  ...  42.22923  478.26580  -10.33823   \n",
              "15  -1.31928  -9.46370   5.53492  ...  10.25585   94.90539   15.95689   \n",
              "16 -33.36843 -24.81437  21.22757  ...  49.93249  -14.47489   40.70590   \n",
              "17  11.75252  -7.62428  -3.65488  ...  50.37614  -40.48205   48.07805   \n",
              "18   1.02668  -7.34736  -0.01184  ... -22.46207  -25.77228 -322.42841   \n",
              "19 -16.40421  -8.29657   9.86817  ...  11.92816  -73.72412   16.19039   \n",
              "\n",
              "        var84     var85      var86      var87     var88       var89     var90  \n",
              "0    15.37344   1.11144  -23.08793   68.40795  -1.82223   -27.46348   2.26327  \n",
              "1    42.87836  -9.90378  -32.22788   70.49388  12.04941    58.43453  26.92061  \n",
              "2    10.93792  -0.07568   43.20130 -115.00698  -0.05859    39.67068  -0.66345  \n",
              "3   -46.67617 -12.51516   82.58061  -72.08993   9.90558   199.62971  18.85382  \n",
              "4   -17.72522  -1.49237   -7.50035   51.76631   7.88713    55.66926  28.74903  \n",
              "5    18.94430  -0.33730    6.09352   35.18381   5.00283   -11.02257   0.02263  \n",
              "6    21.51982   8.17570   35.46251   11.57736   4.50056    -4.62739   1.40192  \n",
              "7    46.99856  -4.09602   56.37650  -18.29975  -0.30633     3.98364  -3.72556  \n",
              "8    17.22100  -0.85210  -15.67150  -26.36257   5.48708    -9.13495   6.08680  \n",
              "9    76.57355  -7.71727    3.26926 -298.49845  11.49326   -89.21804 -15.09719  \n",
              "10  113.58176   9.28727   44.60282  158.00425  -2.59543   109.19723  23.36143  \n",
              "11    2.59467  -4.00958  -47.74886 -170.92864  -5.19009     8.83617  -7.16056  \n",
              "12  157.09656 -27.79449 -137.72740  115.28414  23.00230  -164.02536  51.54138  \n",
              "13 -362.25101 -25.55019  -89.08971 -891.58937  14.11648 -1030.99180  99.28967  \n",
              "14 -103.76858  39.19511  -98.76636 -122.81061  -2.14942  -211.48202 -12.81569  \n",
              "15  -98.15732  -9.64859  -93.52834  -95.82981  20.73063  -562.07671  43.44696  \n",
              "16   58.63692   8.81522   27.28474    5.78046   3.44539   259.10825  10.28525  \n",
              "17   -7.62399   6.51934  -30.46090  -53.87264   4.44627    58.16913  -0.02409  \n",
              "18 -146.57408  13.61588   92.22918 -439.80259  25.73235   157.22967  38.70617  \n",
              "19    9.79606   9.71693   -9.90907  -20.65851   2.34002   -31.57015   1.58400  \n",
              "\n",
              "[20 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e939d6d-c497-414b-8c7b-fa365c42cbfc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>var3</th>\n",
              "      <th>var4</th>\n",
              "      <th>var5</th>\n",
              "      <th>var6</th>\n",
              "      <th>var7</th>\n",
              "      <th>var8</th>\n",
              "      <th>var9</th>\n",
              "      <th>...</th>\n",
              "      <th>var81</th>\n",
              "      <th>var82</th>\n",
              "      <th>var83</th>\n",
              "      <th>var84</th>\n",
              "      <th>var85</th>\n",
              "      <th>var86</th>\n",
              "      <th>var87</th>\n",
              "      <th>var88</th>\n",
              "      <th>var89</th>\n",
              "      <th>var90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>50.54767</td>\n",
              "      <td>0.31568</td>\n",
              "      <td>92.35066</td>\n",
              "      <td>22.38696</td>\n",
              "      <td>-25.51870</td>\n",
              "      <td>-19.04928</td>\n",
              "      <td>20.67345</td>\n",
              "      <td>-5.19943</td>\n",
              "      <td>3.63566</td>\n",
              "      <td>...</td>\n",
              "      <td>6.59753</td>\n",
              "      <td>-50.69577</td>\n",
              "      <td>26.02574</td>\n",
              "      <td>18.94430</td>\n",
              "      <td>-0.33730</td>\n",
              "      <td>6.09352</td>\n",
              "      <td>35.18381</td>\n",
              "      <td>5.00283</td>\n",
              "      <td>-11.02257</td>\n",
              "      <td>0.02263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>50.57546</td>\n",
              "      <td>33.17843</td>\n",
              "      <td>50.53517</td>\n",
              "      <td>11.55217</td>\n",
              "      <td>-27.24764</td>\n",
              "      <td>-8.78206</td>\n",
              "      <td>-12.04282</td>\n",
              "      <td>-9.53930</td>\n",
              "      <td>28.61811</td>\n",
              "      <td>...</td>\n",
              "      <td>11.63681</td>\n",
              "      <td>25.44182</td>\n",
              "      <td>134.62382</td>\n",
              "      <td>21.51982</td>\n",
              "      <td>8.17570</td>\n",
              "      <td>35.46251</td>\n",
              "      <td>11.57736</td>\n",
              "      <td>4.50056</td>\n",
              "      <td>-4.62739</td>\n",
              "      <td>1.40192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>48.26892</td>\n",
              "      <td>8.97526</td>\n",
              "      <td>75.23158</td>\n",
              "      <td>24.04945</td>\n",
              "      <td>-16.02105</td>\n",
              "      <td>-14.09491</td>\n",
              "      <td>8.11871</td>\n",
              "      <td>-1.87566</td>\n",
              "      <td>7.46701</td>\n",
              "      <td>...</td>\n",
              "      <td>18.03989</td>\n",
              "      <td>-58.46192</td>\n",
              "      <td>-65.56438</td>\n",
              "      <td>46.99856</td>\n",
              "      <td>-4.09602</td>\n",
              "      <td>56.37650</td>\n",
              "      <td>-18.29975</td>\n",
              "      <td>-0.30633</td>\n",
              "      <td>3.98364</td>\n",
              "      <td>-3.72556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>49.75468</td>\n",
              "      <td>33.99581</td>\n",
              "      <td>56.73846</td>\n",
              "      <td>2.89581</td>\n",
              "      <td>-2.92429</td>\n",
              "      <td>-26.44413</td>\n",
              "      <td>1.71392</td>\n",
              "      <td>-0.55644</td>\n",
              "      <td>22.08594</td>\n",
              "      <td>...</td>\n",
              "      <td>18.70812</td>\n",
              "      <td>5.20391</td>\n",
              "      <td>-27.75192</td>\n",
              "      <td>17.22100</td>\n",
              "      <td>-0.85210</td>\n",
              "      <td>-15.67150</td>\n",
              "      <td>-26.36257</td>\n",
              "      <td>5.48708</td>\n",
              "      <td>-9.13495</td>\n",
              "      <td>6.08680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>45.17809</td>\n",
              "      <td>46.34234</td>\n",
              "      <td>-40.65357</td>\n",
              "      <td>-2.47909</td>\n",
              "      <td>1.21253</td>\n",
              "      <td>-0.65302</td>\n",
              "      <td>-6.95536</td>\n",
              "      <td>-12.20040</td>\n",
              "      <td>17.02512</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.36742</td>\n",
              "      <td>-87.55285</td>\n",
              "      <td>-70.79677</td>\n",
              "      <td>76.57355</td>\n",
              "      <td>-7.71727</td>\n",
              "      <td>3.26926</td>\n",
              "      <td>-298.49845</td>\n",
              "      <td>11.49326</td>\n",
              "      <td>-89.21804</td>\n",
              "      <td>-15.09719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>39.13076</td>\n",
              "      <td>-23.01763</td>\n",
              "      <td>-36.20583</td>\n",
              "      <td>1.67519</td>\n",
              "      <td>-4.27101</td>\n",
              "      <td>13.01158</td>\n",
              "      <td>8.05718</td>\n",
              "      <td>-8.41088</td>\n",
              "      <td>6.27370</td>\n",
              "      <td>...</td>\n",
              "      <td>32.86051</td>\n",
              "      <td>-26.08461</td>\n",
              "      <td>-186.82429</td>\n",
              "      <td>113.58176</td>\n",
              "      <td>9.28727</td>\n",
              "      <td>44.60282</td>\n",
              "      <td>158.00425</td>\n",
              "      <td>-2.59543</td>\n",
              "      <td>109.19723</td>\n",
              "      <td>23.36143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>37.66498</td>\n",
              "      <td>-34.05910</td>\n",
              "      <td>-17.36060</td>\n",
              "      <td>-26.77781</td>\n",
              "      <td>-39.95119</td>\n",
              "      <td>-20.75000</td>\n",
              "      <td>-0.10231</td>\n",
              "      <td>-0.89972</td>\n",
              "      <td>-1.30205</td>\n",
              "      <td>...</td>\n",
              "      <td>11.18909</td>\n",
              "      <td>45.20614</td>\n",
              "      <td>53.83925</td>\n",
              "      <td>2.59467</td>\n",
              "      <td>-4.00958</td>\n",
              "      <td>-47.74886</td>\n",
              "      <td>-170.92864</td>\n",
              "      <td>-5.19009</td>\n",
              "      <td>8.83617</td>\n",
              "      <td>-7.16056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>26.51957</td>\n",
              "      <td>-148.15762</td>\n",
              "      <td>-13.30095</td>\n",
              "      <td>-7.25851</td>\n",
              "      <td>17.22029</td>\n",
              "      <td>-21.99439</td>\n",
              "      <td>5.51947</td>\n",
              "      <td>3.48418</td>\n",
              "      <td>2.61738</td>\n",
              "      <td>...</td>\n",
              "      <td>23.80442</td>\n",
              "      <td>251.76360</td>\n",
              "      <td>18.81642</td>\n",
              "      <td>157.09656</td>\n",
              "      <td>-27.79449</td>\n",
              "      <td>-137.72740</td>\n",
              "      <td>115.28414</td>\n",
              "      <td>23.00230</td>\n",
              "      <td>-164.02536</td>\n",
              "      <td>51.54138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>37.68491</td>\n",
              "      <td>-26.84185</td>\n",
              "      <td>-27.10566</td>\n",
              "      <td>-14.95883</td>\n",
              "      <td>-5.87200</td>\n",
              "      <td>-21.68979</td>\n",
              "      <td>4.87374</td>\n",
              "      <td>-18.01800</td>\n",
              "      <td>1.52141</td>\n",
              "      <td>...</td>\n",
              "      <td>-67.57637</td>\n",
              "      <td>234.27192</td>\n",
              "      <td>-72.34557</td>\n",
              "      <td>-362.25101</td>\n",
              "      <td>-25.55019</td>\n",
              "      <td>-89.08971</td>\n",
              "      <td>-891.58937</td>\n",
              "      <td>14.11648</td>\n",
              "      <td>-1030.99180</td>\n",
              "      <td>99.28967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>39.11695</td>\n",
              "      <td>-8.29767</td>\n",
              "      <td>-51.37966</td>\n",
              "      <td>-4.42668</td>\n",
              "      <td>-30.06506</td>\n",
              "      <td>-11.95916</td>\n",
              "      <td>-0.85322</td>\n",
              "      <td>-8.86179</td>\n",
              "      <td>11.36680</td>\n",
              "      <td>...</td>\n",
              "      <td>42.22923</td>\n",
              "      <td>478.26580</td>\n",
              "      <td>-10.33823</td>\n",
              "      <td>-103.76858</td>\n",
              "      <td>39.19511</td>\n",
              "      <td>-98.76636</td>\n",
              "      <td>-122.81061</td>\n",
              "      <td>-2.14942</td>\n",
              "      <td>-211.48202</td>\n",
              "      <td>-12.81569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>35.05129</td>\n",
              "      <td>-67.97714</td>\n",
              "      <td>-14.20239</td>\n",
              "      <td>-6.68696</td>\n",
              "      <td>-0.61230</td>\n",
              "      <td>-18.70341</td>\n",
              "      <td>-1.31928</td>\n",
              "      <td>-9.46370</td>\n",
              "      <td>5.53492</td>\n",
              "      <td>...</td>\n",
              "      <td>10.25585</td>\n",
              "      <td>94.90539</td>\n",
              "      <td>15.95689</td>\n",
              "      <td>-98.15732</td>\n",
              "      <td>-9.64859</td>\n",
              "      <td>-93.52834</td>\n",
              "      <td>-95.82981</td>\n",
              "      <td>20.73063</td>\n",
              "      <td>-562.07671</td>\n",
              "      <td>43.44696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>33.63129</td>\n",
              "      <td>-96.14912</td>\n",
              "      <td>-89.38216</td>\n",
              "      <td>-12.11699</td>\n",
              "      <td>13.77252</td>\n",
              "      <td>-6.69377</td>\n",
              "      <td>-33.36843</td>\n",
              "      <td>-24.81437</td>\n",
              "      <td>21.22757</td>\n",
              "      <td>...</td>\n",
              "      <td>49.93249</td>\n",
              "      <td>-14.47489</td>\n",
              "      <td>40.70590</td>\n",
              "      <td>58.63692</td>\n",
              "      <td>8.81522</td>\n",
              "      <td>27.28474</td>\n",
              "      <td>5.78046</td>\n",
              "      <td>3.44539</td>\n",
              "      <td>259.10825</td>\n",
              "      <td>10.28525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>41.38639</td>\n",
              "      <td>-20.78665</td>\n",
              "      <td>51.80155</td>\n",
              "      <td>17.21415</td>\n",
              "      <td>-36.44189</td>\n",
              "      <td>-11.53169</td>\n",
              "      <td>11.75252</td>\n",
              "      <td>-7.62428</td>\n",
              "      <td>-3.65488</td>\n",
              "      <td>...</td>\n",
              "      <td>50.37614</td>\n",
              "      <td>-40.48205</td>\n",
              "      <td>48.07805</td>\n",
              "      <td>-7.62399</td>\n",
              "      <td>6.51934</td>\n",
              "      <td>-30.46090</td>\n",
              "      <td>-53.87264</td>\n",
              "      <td>4.44627</td>\n",
              "      <td>58.16913</td>\n",
              "      <td>-0.02409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>37.45034</td>\n",
              "      <td>11.42615</td>\n",
              "      <td>56.28982</td>\n",
              "      <td>19.58426</td>\n",
              "      <td>-16.43530</td>\n",
              "      <td>2.22457</td>\n",
              "      <td>1.02668</td>\n",
              "      <td>-7.34736</td>\n",
              "      <td>-0.01184</td>\n",
              "      <td>...</td>\n",
              "      <td>-22.46207</td>\n",
              "      <td>-25.77228</td>\n",
              "      <td>-322.42841</td>\n",
              "      <td>-146.57408</td>\n",
              "      <td>13.61588</td>\n",
              "      <td>92.22918</td>\n",
              "      <td>-439.80259</td>\n",
              "      <td>25.73235</td>\n",
              "      <td>157.22967</td>\n",
              "      <td>38.70617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>39.71092</td>\n",
              "      <td>-4.92800</td>\n",
              "      <td>12.88590</td>\n",
              "      <td>-11.87773</td>\n",
              "      <td>2.48031</td>\n",
              "      <td>-16.11028</td>\n",
              "      <td>-16.40421</td>\n",
              "      <td>-8.29657</td>\n",
              "      <td>9.86817</td>\n",
              "      <td>...</td>\n",
              "      <td>11.92816</td>\n",
              "      <td>-73.72412</td>\n",
              "      <td>16.19039</td>\n",
              "      <td>9.79606</td>\n",
              "      <td>9.71693</td>\n",
              "      <td>-9.90907</td>\n",
              "      <td>-20.65851</td>\n",
              "      <td>2.34002</td>\n",
              "      <td>-31.57015</td>\n",
              "      <td>1.58400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows Ã— 91 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e939d6d-c497-414b-8c7b-fa365c42cbfc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e939d6d-c497-414b-8c7b-fa365c42cbfc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e939d6d-c497-414b-8c7b-fa365c42cbfc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncjxI4WdzGrA"
      },
      "source": [
        "### Part (a) -- 7%\n",
        "\n",
        "The data set description text asks us to respect the below train/test split to\n",
        "avoid the \"producer effect\". That is, we want to make sure that no song from a single artist\n",
        "ends up in both the training and test set.\n",
        "\n",
        "Explain why it would be problematic to have\n",
        "some songs from an artist in the training set, and other songs from the same artist in the\n",
        "test set. (Hint: Remember that we want our test accuracy to predict how well the model\n",
        "will perform in practice on a song it hasn't learned about.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NiYlxpFzGrB"
      },
      "source": [
        "df_train = df[:463715]\n",
        "df_test = df[463715:]\n",
        "\n",
        "# convert to numpy\n",
        "train_xs = df_train[x_labels].to_numpy()\n",
        "train_ts = df_train[t_label].to_numpy()\n",
        "test_xs = df_test[x_labels].to_numpy()\n",
        "test_ts = df_test[t_label].to_numpy()\n",
        "\n",
        "# Explanation:\n",
        "# Since most of the songs of an artist were written in the same century, it could be argued that splitting a single artist's song into both \n",
        "# training and testing might lead to an over-confident result as the model might recognize the artist and immidietly classify the song into the dominant century\n",
        "# of the artist. The result is that song's century being classified accorsing on the artist."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYSzd4XUzGrB"
      },
      "source": [
        "### Part (b) -- 7%\n",
        "\n",
        "It can be beneficial to **normalize** the columns, so that each column (feature)\n",
        "has the *same* mean and standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPuWLksJzGrB"
      },
      "source": [
        "feature_means = df_train.mean()[1:].to_numpy() # the [1:] removes the mean of the \"year\" field\n",
        "feature_stds  = df_train.std()[1:].to_numpy()\n",
        "\n",
        "train_norm_xs = (train_xs - feature_means) / feature_stds\n",
        "test_norm_xs = (test_xs - feature_means) / feature_stds"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4zmZk6ezGrC"
      },
      "source": [
        "Notice how in our code, we normalized the test set using the *training data means and standard deviations*.\n",
        "This is *not* a bug.\n",
        "\n",
        "Explain why it would be improper to compute and use test set means\n",
        "and standard deviations. (Hint: Remember what we want to use the test accuracy to measure.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxZy6brwzGrC"
      },
      "source": [
        "# Explanation:\n",
        "# The splitting between training and testing is \"artificial\" - the testing is supposed to represent the model's performence on new unknown data.\n",
        "# Thus, the only \"known\" parameters are the training parameters - the testing parameters are pretented to be hidden. "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4GqL5J_zGrC"
      },
      "source": [
        "### Part (c) -- 7%\n",
        "\n",
        "Finally, we'll move some of the data in our training set into a validation set.\n",
        "\n",
        "Explain why we should limit how many times we use the test set, and that we should use the validation\n",
        "set during the model building process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsXv1U3gzGrC"
      },
      "source": [
        "# shuffle the training set\n",
        "reindex = np.random.permutation(len(train_xs))\n",
        "train_xs = train_xs[reindex]\n",
        "train_norm_xs = train_norm_xs[reindex]\n",
        "train_ts = train_ts[reindex]\n",
        "\n",
        "# use the first 50000 elements of `train_xs` as the validation set\n",
        "train_xs, val_xs           = train_xs[50000:], train_xs[:50000]\n",
        "train_norm_xs, val_norm_xs = train_norm_xs[50000:], train_norm_xs[:50000]\n",
        "train_ts, val_ts           = train_ts[50000:], train_ts[:50000]\n",
        "\n",
        "# Explanation:\n",
        "# We should limit how many times we use the test data, as we do not want to model to adjust (fit) according to the test data (because it would not allow us to examine\n",
        "# the accuracy and performance of our model later - when using the test set), but rather only to the training set.\n",
        "# In order to validate a specific model structure (and specifically - the hyperparameters) we take a small portion of the training set - namely the \"validation\" set.\n",
        " "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy4lt445zGrD"
      },
      "source": [
        "## Part 2. Classification (79%)\n",
        "\n",
        "We will first build a *classification* model to perform decade classification.\n",
        "These helper functions are written for you. All other code that you write in this section should be vectorized whenever possible (i.e., avoid unnecessary loops)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6BA_s-kzGrD"
      },
      "source": [
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "def cross_entropy(t, y):\n",
        "  return -t * np.log(y) - (1 - t) * np.log(1 - y)\n",
        "\n",
        "def cost(y, t):\n",
        "  return np.mean(cross_entropy(t, y))\n",
        "\n",
        "def get_accuracy(y, t):\n",
        "  acc = 0\n",
        "  N = 0\n",
        "  for i in range(len(y)):\n",
        "    N += 1\n",
        "    if (y[i] >= 0.5 and t[i] == 1) or (y[i] < 0.5 and t[i] == 0):\n",
        "      acc += 1\n",
        "  return acc / N"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8ZIfooBzGrD"
      },
      "source": [
        "### Part (a) -- 7%\n",
        "\n",
        "Write a function `pred` that computes the prediction `y` based on logistic regression, i.e., a single layer with weights `w` and bias `b`. The output is given by: \n",
        "\\begin{equation}\n",
        "y = \\sigma({\\bf w}^T {\\bf x} + b),\n",
        "\\end{equation}\n",
        "where the value of $y$ is an estimate of the probability that the song is released in the current century, namely ${\\rm year} =1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naY5mT4_zGrD"
      },
      "source": [
        "def pred(w, b, X):\n",
        "  \"\"\"\n",
        "  Returns the prediction `y` of the target based on the weights `w` and scalar bias `b`.\n",
        "\n",
        "  Preconditions: np.shape(w) == (90,)\n",
        "                 type(b) == float\n",
        "                 np.shape(X) = (N, 90) for some N\n",
        "\n",
        "  >>> pred(np.zeros(90), 1, np.ones([2, 90]))\n",
        "  array([0.73105858, 0.73105858]) # It's okay if your output differs in the last decimals\n",
        "  \"\"\"\n",
        "  # Code:\n",
        "  return sigmoid(np.transpose(w)@np.transpose(X)+b)\n",
        "\n",
        "# pred(np.zeros(90), 1, np.ones([2, 90]))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxNdmSd3zGrE"
      },
      "source": [
        "### Part (b) -- 7%\n",
        "\n",
        "Write a function `derivative_cost` that computes and returns the gradients \n",
        "$\\frac{\\partial\\mathcal{L}}{\\partial {\\bf w}}$ and\n",
        "$\\frac{\\partial\\mathcal{L}}{\\partial b}$. Here, `X` is the input, `y` is the prediction, and `t` is the true label.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P80bu7qmzGrE"
      },
      "source": [
        "def derivative_cost(X, y, t):\n",
        "  \"\"\"\n",
        "  Returns a tuple containing the gradients dLdw and dLdb.\n",
        "\n",
        "  Precondition: np.shape(X) == (N, 90) for some N\n",
        "                np.shape(y) == (N,)\n",
        "                np.shape(t) == (N,)\n",
        "\n",
        "  Postcondition: np.shape(dLdw) = (90,)\n",
        "           type(dLdb) = float\n",
        "  \"\"\"\n",
        "  # Code:\n",
        "  dLdw = X.T @ (y-t) / (X.shape[0]) \n",
        "  dLdb = np.mean(y - t)\n",
        "  return dLdw , dLdb"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okPRGM3BjKe2"
      },
      "source": [
        "# **Explenation on Gradients**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHfmPVdsg0eX"
      },
      "source": [
        "**Gradients explanation:**\n",
        "\n",
        "In order to calculate the partial derivatives $\\dfrac{\\partial L}{\\partial w}$ and $\\dfrac{\\partial L}{\\partial b}$, we will use the \"Chain-Rule\", as follows:\n",
        "\n",
        "$$\\dfrac{\\partial L}{\\partial w}=\\dfrac{\\partial L}{\\partial y_n}\\cdot \\dfrac{\\partial y_n}{\\partial z_n}\\cdot \\dfrac{\\partial z_n}{\\partial w}$$\n",
        "\n",
        "$$ \\dfrac{\\partial L}{\\partial b}=\\dfrac{\\partial L}{\\partial y_n}\\cdot \\dfrac{\\partial y_n}{\\partial z_n}\\cdot \\dfrac{\\partial z_n}{\\partial b}$$\n",
        "\n",
        "For that purpose, shown below are the functions explicitly, with the corresponding arguments:\n",
        "$$L(y_n)= \\frac{1}{N}\\sum_{n=1}^{N} \\left[-t_n\\cdot log(y_n)-(1-t_n)\\cdot log(1-y_n) \\right]$$\n",
        "$$y_n(z_n)= \\frac{1}{1+e^{-z_n}}$$\n",
        "$$z_n(w)= w^T\\cdot x_n + b$$\n",
        "\n",
        "This allows calculating each derivative separately in the following manner:\n",
        "$$\\dfrac{\\partial L}{\\partial y_n} =\\frac{1}{N}\\sum_{n=1}^{N} \\left[ \\frac{-t_n}{y_n}+\\frac{1-t_n}{1-y_n} \\right] $$\n",
        "\n",
        "$$\\dfrac{\\partial y_n}{\\partial z_n} = -1(1+e^{-z_n})^{-2}\\cdot (-e^{-z_n}) = \\frac{1}{e^{z_n}(1+e^{-z_n})}\\cdot \\frac{1}{1+e^{-z_n}}=(1-y_n)\\cdot y_n $$\n",
        "$$\\dfrac{\\partial z_n}{\\partial w} = x_n $$\n",
        "$$\\dfrac{\\partial z_n}{\\partial b} = 1 $$\n",
        "\n",
        "Plugging these results gives:\n",
        "\n",
        "$$ \\dfrac{\\partial L}{\\partial w}=\\frac{1}{N}\\sum_{n=1}^{N} \\left[(-t_n(1-y_n)+(1-t_n)y_n)\\cdot x_n \\right] = \\frac{1}{N}\\sum_{n=1}^{N} \\left[(y_n-t_n)\\cdot x_n \\right] $$\n",
        "$$ \\dfrac{\\partial L}{\\partial b}=\\frac{1}{N}\\sum_{n=1}^{N} \\left[(-t_n(1-y_n)+(1-t_n)y_n) \\right] = \\frac{1}{N}\\sum_{n=1}^{N} \\left[(y_n-t_n) \\right] $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhQXAKd4zGrE"
      },
      "source": [
        "### Part (c) -- 7%\n",
        "\n",
        "We can check that our derivative is implemented correctly using the finite difference rule. In 1D, the\n",
        "finite difference rule tells us that for small $h$, we should have\n",
        "\n",
        "$$\\frac{f(x+h) - f(x)}{h} \\approx f'(x)$$\n",
        "\n",
        "Show that $\\frac{\\partial\\mathcal{L}}{\\partial b}$  is implement correctly\n",
        "by comparing the result from `derivative_cost` with the empirical cost derivative computed using the above numerical approximation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpRTD-fozGrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03414c67-e5dd-4863-d79e-15004a59916a"
      },
      "source": [
        "# Code\n",
        "\n",
        "N = 10\n",
        "h = 1e-5\n",
        "\n",
        "X = train_norm_xs[0:N,:]\n",
        "t = train_ts[0:N,0]\n",
        "w = np.zeros(90)\n",
        "b = 1\n",
        "\n",
        "\n",
        "y_0 = pred (w, b, X)\n",
        "y_1 = pred (w, b+h, X)\n",
        "\n",
        "r1 = (cost(y_1,t)-cost(y_0,t))/h\n",
        "_ , r2 = derivative_cost(X, y_0, t)\n",
        "\n",
        "print(\"The analytical results is -\", r1)\n",
        "print(\"The algorithm results is - \", r2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The analytical results is - 0.23105956170610395\n",
            "The algorithm results is -  0.23105857863000487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTiplTPhzGrF"
      },
      "source": [
        "### Part (d) -- 7%\n",
        "\n",
        "Show that $\\frac{\\partial\\mathcal{L}}{\\partial {\\bf w}}$  is implement correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVTsHgnPzGrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3b0c23-96e0-43d8-f09f-ffdce63b7b34"
      },
      "source": [
        "# Code:\n",
        "H = np.zeros(90)\n",
        "r1 = np.zeros(90)\n",
        "\n",
        "for ii in range(w.shape[0]):\n",
        "  H[ii] = h\n",
        "  y_1 = pred (w+H, b, X)\n",
        "  r1_i = (cost(y_1,t)-cost(y_0,t))/h\n",
        "  H[ii] = 0\n",
        "  r1[ii]=r1_i\n",
        "r2 , _ = derivative_cost(X, y_0, t)\n",
        "\n",
        "print(\"The analytical results is -\", r1)\n",
        "print(\"The algorithm results is - \", r2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The analytical results is - [-0.06364266 -0.13153996  0.20528129 -0.28099     0.13301351 -0.19228524\n",
            " -0.27933358  0.02413083 -0.03310985 -0.05600571  0.04955929  0.06232444\n",
            " -0.09875788 -0.20843031 -0.12814159 -0.17721461 -0.05584892 -0.29127539\n",
            " -0.20070973 -0.31863648 -0.11245108 -0.33837597 -0.2264118  -0.14407441\n",
            " -0.08717949 -0.08453772  0.23336714 -0.02529073 -0.00977624 -0.10193357\n",
            "  0.05202723 -0.02835431  0.15055     0.08830999  0.02389949 -0.08824078\n",
            "  0.10091475 -0.27257869 -0.24208573  0.0576447  -0.1896169  -0.01706544\n",
            "  0.07336851 -0.1327365   0.08203633  0.10017142 -0.0789143  -0.02459448\n",
            " -0.05100732  0.03788862 -0.10272269  0.13039516 -0.08472043  0.05945005\n",
            "  0.13503607  0.09095089 -0.08101613  0.01033807  0.04925059  0.20320462\n",
            " -0.0917192   0.00489008  0.16900169  0.11883603 -0.0538668   0.30849098\n",
            "  0.19906072 -0.05276851  0.07710778 -0.03885614  0.03112519  0.22159767\n",
            " -0.23742395 -0.18510516  0.1391413   0.05229919 -0.07853399  0.08705904\n",
            "  0.018058    0.14086068 -0.07870954  0.01524341  0.04051111 -0.16149795\n",
            "  0.06260802 -0.1227428  -0.02063792 -0.2111495  -0.1107308  -0.03519462]\n",
            "The algorithm results is -  [-0.0636433  -0.13154022  0.20528095 -0.28099061  0.13301241 -0.19228562\n",
            " -0.27933412  0.02412968 -0.03311063 -0.05600698  0.04955818  0.06232346\n",
            " -0.09875924 -0.20843065 -0.12814226 -0.17721604 -0.05584946 -0.29127639\n",
            " -0.20071073 -0.31863813 -0.11245144 -0.33837685 -0.22641245 -0.14407469\n",
            " -0.08717965 -0.08453786  0.2333635  -0.02529312 -0.00977648 -0.1019342\n",
            "  0.05202698 -0.0283545   0.15054948  0.08830956  0.02389886 -0.08824116\n",
            "  0.10091419 -0.27257999 -0.24208703  0.05764414 -0.18961733 -0.01706574\n",
            "  0.07336804 -0.13273687  0.08203615  0.10016906 -0.07891451 -0.02459617\n",
            " -0.05100765  0.03788789 -0.10272295  0.13039463 -0.08472095  0.05944961\n",
            "  0.1350349   0.09095043 -0.08101644  0.01033687  0.04925019  0.20320348\n",
            " -0.09171946  0.00488964  0.16899992  0.11883575 -0.05386833  0.30849034\n",
            "  0.19906019 -0.05276871  0.07710754 -0.03885661  0.03112505  0.22159731\n",
            " -0.23742458 -0.18510609  0.13914096  0.05229852 -0.07853404  0.08705828\n",
            "  0.01805726  0.14086019 -0.07870977  0.01524282  0.04051047 -0.1614986\n",
            "  0.06260739 -0.12274306 -0.02063816 -0.21115003 -0.11073098 -0.03519487]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgBTPF_2zGrG"
      },
      "source": [
        "### Part (e) -- 7%\n",
        "\n",
        "Now that you have a gradient function that works, we can actually run gradient descent. \n",
        "Complete the following code that will run stochastic: gradient descent training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW4DEuuPzGrG"
      },
      "source": [
        "def run_gradient_descent(train_norm_xs, train_ts, val_norm_xs, val_ts, w0, b0, mu=0.1, batch_size=100, max_iters=100):\n",
        "  \"\"\"Return the values of (w, b) after running gradient descent for max_iters.\n",
        "  We use:\n",
        "    - train_norm_xs and train_ts as the training set\n",
        "    - val_norm_xs and val_ts as the test set\n",
        "    - mu as the learning rate\n",
        "    - (w0, b0) as the initial values of (w, b)\n",
        "\n",
        "  Precondition: np.shape(w0) == (90,)\n",
        "                type(b0) == float\n",
        " \n",
        "  Postcondition: np.shape(w) == (90,)\n",
        "                 type(b) == float\n",
        "  \"\"\"\n",
        "  w = w0\n",
        "  b = b0\n",
        "  iter = 0\n",
        "  val_log = {'accuracy': [], 'cost': []}\n",
        "\n",
        "  while iter < max_iters:\n",
        "    # shuffle the training set:\n",
        "    reindex = np.random.permutation(len(train_norm_xs))\n",
        "    train_norm_xs = train_norm_xs[reindex]\n",
        "    train_ts = train_ts[reindex]\n",
        "\n",
        "    for i in range(0, len(train_norm_xs), batch_size): # iterate over each minibatch\n",
        "      # minibatch that we are working with:\n",
        "      X = train_norm_xs[i:(i + batch_size)]\n",
        "      t = train_ts[i:(i + batch_size), 0]\n",
        "\n",
        "      # since len(train_norm_xs) does not divide batch_size evenly, we will skip over\n",
        "      # the \"last\" minibatch\n",
        "      if np.shape(X)[0] != batch_size:\n",
        "        continue\n",
        "      \n",
        "      # compute the prediction\n",
        "      y = pred (w,b,X)\n",
        "\n",
        "      # update w and b\n",
        "      dLdw , dLdb = derivative_cost(X, y, t)\n",
        "      w += -mu*dLdw\n",
        "      b += -mu*dLdb\n",
        "\n",
        "      # increment the iteration count\n",
        "      iter += 1\n",
        "      # compute and print the *validation* loss and accuracy\n",
        "      if (iter % 10 == 0):\n",
        "        val_y = pred(w,b,val_norm_xs)\n",
        "        val_cost = cost(val_y,val_ts)\n",
        "        val_acc = get_accuracy(val_y, val_ts)\n",
        "        print(\"Iter %d. [Val Acc %.0f%%, Loss %f]\" % (\n",
        "                iter, val_acc * 100, val_cost))\n",
        "        # Log validation data\n",
        "        val_log[\"accuracy\"].append(val_acc*100)\n",
        "        val_log[\"cost\"].append(val_cost)\n",
        "\n",
        "      if iter >= max_iters:\n",
        "        break\n",
        "\n",
        "      # Think what parameters you should return for further use\n",
        "      \n",
        "  return val_log\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MqzT0jGzGrH"
      },
      "source": [
        "### Part (f) -- 7%\n",
        "\n",
        "Call `run_gradient_descent` with the weights and biases all initialized to zero.\n",
        "Show that if the learning rate $\\mu$ is too small, then convergence is slow.\n",
        "Also, show that if $\\mu$ is too large, then the optimization algorirthm does not converge. The demonstration should be made using plots showing these effects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE32Iqo6zGrH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3de271fb-e619-4232-8057-853e1ae24d58"
      },
      "source": [
        "# Code:\n",
        "w0 = np.zeros(90)\n",
        "b0 = np.zeros(1)[0]\n",
        "mu_vec = [1e-2, 1e-1, 1e-0]\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize=(10, 5))\n",
        "iter=250;\n",
        "\n",
        "\n",
        "for mu in mu_vec:\n",
        "  print('mu = ',mu)\n",
        "  log = run_gradient_descent(train_norm_xs[:100000], train_ts[:100000], val_norm_xs[:5000],val_ts[:5000], w0, b0, mu, batch_size=100, max_iters=iter)\n",
        "  # log = run_gradient_descent(train_norm_xs, train_ts, val_norm_xs,val_ts, w0, b0, mu, batch_size=100, max_iters=1000)\n",
        "  ax[0].plot(np.arange(0,iter,10),log[\"accuracy\"][:],label = \"\\mu = \"+str(mu))\n",
        "  ax[1].plot(np.arange(0,iter,10),log[\"cost\"][:],label = \"\\mu = \"+str(mu))\n",
        "\n",
        "ax[0].set_xlabel('# Iteration')\n",
        "ax[0].set_ylabel('[%]')\n",
        "ax[1].set_xlabel('# Iteration')\n",
        "ax[0].set_title('Accuracy')\n",
        "ax[1].set_title('Loss')\n",
        "ax[1].legend(loc='center left')\n",
        "ax[0].grid()\n",
        "ax[1].grid()\n",
        "plt.show()\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mu =  0.01\n",
            "Iter 10. [Val Acc 65%, Loss 0.693142]\n",
            "Iter 20. [Val Acc 66%, Loss 0.693794]\n",
            "Iter 30. [Val Acc 67%, Loss 0.693913]\n",
            "Iter 40. [Val Acc 67%, Loss 0.694628]\n",
            "Iter 50. [Val Acc 67%, Loss 0.695808]\n",
            "Iter 60. [Val Acc 67%, Loss 0.697049]\n",
            "Iter 70. [Val Acc 67%, Loss 0.698732]\n",
            "Iter 80. [Val Acc 67%, Loss 0.700363]\n",
            "Iter 90. [Val Acc 67%, Loss 0.701533]\n",
            "Iter 100. [Val Acc 67%, Loss 0.702734]\n",
            "Iter 110. [Val Acc 68%, Loss 0.703542]\n",
            "Iter 120. [Val Acc 68%, Loss 0.705794]\n",
            "Iter 130. [Val Acc 68%, Loss 0.706860]\n",
            "Iter 140. [Val Acc 68%, Loss 0.707797]\n",
            "Iter 150. [Val Acc 68%, Loss 0.709459]\n",
            "Iter 160. [Val Acc 68%, Loss 0.710943]\n",
            "Iter 170. [Val Acc 68%, Loss 0.711574]\n",
            "Iter 180. [Val Acc 69%, Loss 0.713001]\n",
            "Iter 190. [Val Acc 69%, Loss 0.713781]\n",
            "Iter 200. [Val Acc 69%, Loss 0.714303]\n",
            "Iter 210. [Val Acc 69%, Loss 0.714729]\n",
            "Iter 220. [Val Acc 69%, Loss 0.716191]\n",
            "Iter 230. [Val Acc 69%, Loss 0.717455]\n",
            "Iter 240. [Val Acc 69%, Loss 0.718062]\n",
            "Iter 250. [Val Acc 69%, Loss 0.719474]\n",
            "mu =  0.1\n",
            "Iter 10. [Val Acc 69%, Loss 0.736223]\n",
            "Iter 20. [Val Acc 70%, Loss 0.739838]\n",
            "Iter 30. [Val Acc 70%, Loss 0.751845]\n",
            "Iter 40. [Val Acc 71%, Loss 0.762866]\n",
            "Iter 50. [Val Acc 70%, Loss 0.764908]\n",
            "Iter 60. [Val Acc 70%, Loss 0.767652]\n",
            "Iter 70. [Val Acc 71%, Loss 0.771108]\n",
            "Iter 80. [Val Acc 71%, Loss 0.777672]\n",
            "Iter 90. [Val Acc 71%, Loss 0.775156]\n",
            "Iter 100. [Val Acc 70%, Loss 0.781141]\n",
            "Iter 110. [Val Acc 71%, Loss 0.786235]\n",
            "Iter 120. [Val Acc 71%, Loss 0.783683]\n",
            "Iter 130. [Val Acc 71%, Loss 0.790831]\n",
            "Iter 140. [Val Acc 72%, Loss 0.788506]\n",
            "Iter 150. [Val Acc 71%, Loss 0.801623]\n",
            "Iter 160. [Val Acc 72%, Loss 0.806992]\n",
            "Iter 170. [Val Acc 71%, Loss 0.811413]\n",
            "Iter 180. [Val Acc 71%, Loss 0.808342]\n",
            "Iter 190. [Val Acc 72%, Loss 0.805069]\n",
            "Iter 200. [Val Acc 72%, Loss 0.807793]\n",
            "Iter 210. [Val Acc 72%, Loss 0.821307]\n",
            "Iter 220. [Val Acc 72%, Loss 0.825182]\n",
            "Iter 230. [Val Acc 72%, Loss 0.818800]\n",
            "Iter 240. [Val Acc 72%, Loss 0.814815]\n",
            "Iter 250. [Val Acc 72%, Loss 0.810889]\n",
            "mu =  1.0\n",
            "Iter 10. [Val Acc 68%, Loss 0.876014]\n",
            "Iter 20. [Val Acc 68%, Loss 1.037741]\n",
            "Iter 30. [Val Acc 64%, Loss 1.026670]\n",
            "Iter 40. [Val Acc 68%, Loss 1.056441]\n",
            "Iter 50. [Val Acc 71%, Loss 1.039695]\n",
            "Iter 60. [Val Acc 68%, Loss 0.948346]\n",
            "Iter 70. [Val Acc 71%, Loss 1.061803]\n",
            "Iter 80. [Val Acc 70%, Loss 1.017970]\n",
            "Iter 90. [Val Acc 70%, Loss 0.998768]\n",
            "Iter 100. [Val Acc 71%, Loss 1.019390]\n",
            "Iter 110. [Val Acc 70%, Loss 1.040131]\n",
            "Iter 120. [Val Acc 71%, Loss 0.936641]\n",
            "Iter 130. [Val Acc 69%, Loss 0.991751]\n",
            "Iter 140. [Val Acc 71%, Loss 1.032140]\n",
            "Iter 150. [Val Acc 69%, Loss 0.992528]\n",
            "Iter 160. [Val Acc 71%, Loss 0.981392]\n",
            "Iter 170. [Val Acc 69%, Loss 0.982300]\n",
            "Iter 180. [Val Acc 71%, Loss 0.959424]\n",
            "Iter 190. [Val Acc 71%, Loss 1.034585]\n",
            "Iter 200. [Val Acc 70%, Loss 0.952370]\n",
            "Iter 210. [Val Acc 70%, Loss 0.941794]\n",
            "Iter 220. [Val Acc 70%, Loss 0.943754]\n",
            "Iter 230. [Val Acc 69%, Loss 0.946059]\n",
            "Iter 240. [Val Acc 70%, Loss 0.962977]\n",
            "Iter 250. [Val Acc 69%, Loss 1.136867]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S44GmUZ12o-g"
      },
      "source": [
        "**Explain and discuss your results here:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ5HlDFAzGrH"
      },
      "source": [
        "### Part (g) -- 7%\n",
        "\n",
        "Find the optimial value of ${\\bf w}$ and $b$ using your code. Explain how you chose\n",
        "the learning rate $\\mu$ and the batch size. Show plots demostrating good and bad behaviours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dFOFSwgzGrI"
      },
      "source": [
        "w0 = np.random.randn(90)\n",
        "b0 = np.random.randn(1)[0]\n",
        "\n",
        "# Write your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkZt7_932zX2"
      },
      "source": [
        "**Explain and discuss your results here:**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KrQqSj2zGrI"
      },
      "source": [
        "### Part (h) -- 15%\n",
        "\n",
        "Using the values of `w` and `b` from part (g), compute your training accuracy, validation accuracy,\n",
        "and test accuracy. Are there any differences between those three values? If so, why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuKw2mLozGrI"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "train_acc = ...\n",
        "val_acc = ...\n",
        "test_acc = ...\n",
        "\n",
        "print('train_acc = ', train_acc, ' val_acc = ', val_acc, ' test_acc = ', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXZa1u6920M3"
      },
      "source": [
        "**Explain and discuss your results here:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4eP2Yh1zGrI"
      },
      "source": [
        "### Part (i) -- 15%\n",
        "\n",
        "Writing a classifier like this is instructive, and helps you understand what happens when\n",
        "we train a model. However, in practice, we rarely write model building and training code\n",
        "from scratch. Instead, we typically use one of the well-tested libraries available in a package.\n",
        "\n",
        "Use `sklearn.linear_model.LogisticRegression` to build a linear classifier, and make predictions about the test set. Start by reading the\n",
        "[API documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
        "\n",
        "Compute the training, validation and test accuracy of this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24LCfAa1zGrJ"
      },
      "source": [
        "import sklearn.linear_model\n",
        "\n",
        "model = ...\n",
        "\n",
        "train_acc = ...\n",
        "val_acc = ...\n",
        "test_acc = ...\n",
        "\n",
        "print('train_acc = ', train_acc, ' val_acc = ', val_acc, ' test_acc = ', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRqucdV923tG"
      },
      "source": [
        "**This parts helps by checking if the code worked.**\n",
        "**Check if you get similar results, if not repair your code**\n"
      ]
    }
  ]
}