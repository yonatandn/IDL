{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yonatandn/IDL/blob/develop/Assignment1_group58.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bhfIKbQzGq2"
      },
      "source": [
        "# Assignment 1. Music Century Classification\n",
        "\n",
        "**Assignment Responsible**: Natalie Lang.\n",
        "Te\n",
        "In this assignment, we will build models to predict which\n",
        "**century** a piece of music was released.  We will be using the \"YearPredictionMSD Data Set\"\n",
        "based on the Million Song Dataset. The data is available to download from the UCI \n",
        "Machine Learning Repository. Here are some links about the data:\n",
        "\n",
        "- https://archive.ics.uci.edu/ml/datasets/yearpredictionmsd\n",
        "- http://millionsongdataset.com/pages/tasks-demos/#yearrecognition\n",
        "\n",
        "Note that you are note allowed to import additional packages **(especially not PyTorch)**. One of the objectives is to understand how the training procedure actually operates, before working with PyTorch's autograd engine which does it all for us.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47oq1vy5PUIV"
      },
      "source": [
        "## Question 1. Data (21%)\n",
        "\n",
        "Start by setting up a Google Colab notebook in which to do your work.\n",
        "Since you are working with a partner, you might find this link helpful:\n",
        "\n",
        "- https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb\n",
        "\n",
        "The recommended way to work together is pair coding, where you and your partner are sitting together and writing code together. \n",
        "\n",
        "To process and read the data, we use the popular `pandas` package for data analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aFWpuNSzGq9"
      },
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7UWL6mFzGq-"
      },
      "source": [
        "Now that your notebook is set up, we can load the data into the notebook. The code below provides\n",
        "two ways of loading the data: directly from the internet, or through mounting Google Drive.\n",
        "The first method is easier but slower, and the second method is a bit involved at first, but\n",
        "can save you time later on. You will need to mount Google Drive for later assignments, so we recommend\n",
        "figuring how to do that now.\n",
        "\n",
        "Here are some resources to help you get started:\n",
        "\n",
        "- http.://colab.research.google.com/notebooks/io.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY6PrfV4zGq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93e8a59-1691-4dff-cd87-d65a70e95086"
      },
      "source": [
        "load_from_drive = True\n",
        "\n",
        "if not load_from_drive:\n",
        "  csv_path = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\"\n",
        "else:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  csv_path = '/content/gdrive/MyDrive/IDL_Data/YearPredictionMSD.txt.zip' \n",
        "\n",
        "t_label = [\"year\"]\n",
        "x_labels = [\"var%d\" % i for i in range(1, 91)]\n",
        "df = pandas.read_csv(csv_path, names=t_label + x_labels)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgB83beNzGq_"
      },
      "source": [
        "Now that the data is loaded to your Colab notebook, you should be able to display the Pandas\n",
        "DataFrame `df` as a table:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5bBEnj3zGq_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "aaaf7aed-64a1-4f60-86f5-e04e529add5a"
      },
      "source": [
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        year      var1      var2      var3      var4      var5      var6  \\\n",
              "0       2001  49.94357  21.47114  73.07750   8.74861 -17.40628 -13.09905   \n",
              "1       2001  48.73215  18.42930  70.32679  12.94636 -10.32437 -24.83777   \n",
              "2       2001  50.95714  31.85602  55.81851  13.41693  -6.57898 -18.54940   \n",
              "3       2001  48.24750  -1.89837  36.29772   2.58776   0.97170 -26.21683   \n",
              "4       2001  50.97020  42.20998  67.09964   8.46791 -15.85279 -16.81409   \n",
              "...      ...       ...       ...       ...       ...       ...       ...   \n",
              "515340  2006  51.28467  45.88068  22.19582  -5.53319  -3.61835 -16.36914   \n",
              "515341  2006  49.87870  37.93125  18.65987  -3.63581 -27.75665 -18.52988   \n",
              "515342  2006  45.12852  12.65758 -38.72018   8.80882 -29.29985  -2.28706   \n",
              "515343  2006  44.16614  32.38368  -3.34971  -2.49165 -19.59278 -18.67098   \n",
              "515344  2005  51.85726  59.11655  26.39436  -5.46030 -20.69012 -19.95528   \n",
              "\n",
              "            var7      var8      var9  ...     var81      var82      var83  \\\n",
              "0      -25.01202 -12.23257   7.83089  ...  13.01620  -54.40548   58.99367   \n",
              "1        8.76630  -0.92019  18.76548  ...   5.66812  -19.68073   33.04964   \n",
              "2       -3.27872  -2.35035  16.07017  ...   3.03800   26.05866  -50.92779   \n",
              "3        5.05097 -10.34124   3.55005  ...  34.57337 -171.70734  -16.96705   \n",
              "4      -12.48207  -9.37636  12.63699  ...   9.92661  -55.95724   64.92712   \n",
              "...          ...       ...       ...  ...       ...        ...        ...   \n",
              "515340   2.12652   5.18160  -8.66890  ...   4.81440   -3.75991  -30.92584   \n",
              "515341   7.76108   3.56109  -2.50351  ...  32.38589  -32.75535  -61.05473   \n",
              "515342 -18.40424 -22.28726  -4.52429  ... -18.73598  -71.15954 -123.98443   \n",
              "515343   8.78428   4.02039 -12.01230  ...  67.16763  282.77624   -4.63677   \n",
              "515344  -6.72771   2.29590  10.31018  ... -11.50511  -69.18291   60.58456   \n",
              "\n",
              "            var84     var85     var86      var87     var88      var89  \\\n",
              "0        15.37344   1.11144 -23.08793   68.40795  -1.82223  -27.46348   \n",
              "1        42.87836  -9.90378 -32.22788   70.49388  12.04941   58.43453   \n",
              "2        10.93792  -0.07568  43.20130 -115.00698  -0.05859   39.67068   \n",
              "3       -46.67617 -12.51516  82.58061  -72.08993   9.90558  199.62971   \n",
              "4       -17.72522  -1.49237  -7.50035   51.76631   7.88713   55.66926   \n",
              "...           ...       ...       ...        ...       ...        ...   \n",
              "515340   26.33968  -5.03390  21.86037 -142.29410   3.42901  -41.14721   \n",
              "515341   56.65182  15.29965  95.88193  -10.63242  12.96552   92.11633   \n",
              "515342  121.26989  10.89629  34.62409 -248.61020  -6.07171   53.96319   \n",
              "515343  144.00125  21.62652 -29.72432   71.47198  20.32240   14.83107   \n",
              "515344   28.64599  -4.39620 -64.56491  -45.61012  -5.51512   32.35602   \n",
              "\n",
              "           var90  \n",
              "0        2.26327  \n",
              "1       26.92061  \n",
              "2       -0.66345  \n",
              "3       18.85382  \n",
              "4       28.74903  \n",
              "...          ...  \n",
              "515340 -15.46052  \n",
              "515341  10.88815  \n",
              "515342  -8.09364  \n",
              "515343  39.74909  \n",
              "515344  12.17352  \n",
              "\n",
              "[515345 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43bad1fe-af8f-4388-a2c8-305d493fbde4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>var3</th>\n",
              "      <th>var4</th>\n",
              "      <th>var5</th>\n",
              "      <th>var6</th>\n",
              "      <th>var7</th>\n",
              "      <th>var8</th>\n",
              "      <th>var9</th>\n",
              "      <th>...</th>\n",
              "      <th>var81</th>\n",
              "      <th>var82</th>\n",
              "      <th>var83</th>\n",
              "      <th>var84</th>\n",
              "      <th>var85</th>\n",
              "      <th>var86</th>\n",
              "      <th>var87</th>\n",
              "      <th>var88</th>\n",
              "      <th>var89</th>\n",
              "      <th>var90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515340</th>\n",
              "      <td>2006</td>\n",
              "      <td>51.28467</td>\n",
              "      <td>45.88068</td>\n",
              "      <td>22.19582</td>\n",
              "      <td>-5.53319</td>\n",
              "      <td>-3.61835</td>\n",
              "      <td>-16.36914</td>\n",
              "      <td>2.12652</td>\n",
              "      <td>5.18160</td>\n",
              "      <td>-8.66890</td>\n",
              "      <td>...</td>\n",
              "      <td>4.81440</td>\n",
              "      <td>-3.75991</td>\n",
              "      <td>-30.92584</td>\n",
              "      <td>26.33968</td>\n",
              "      <td>-5.03390</td>\n",
              "      <td>21.86037</td>\n",
              "      <td>-142.29410</td>\n",
              "      <td>3.42901</td>\n",
              "      <td>-41.14721</td>\n",
              "      <td>-15.46052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515341</th>\n",
              "      <td>2006</td>\n",
              "      <td>49.87870</td>\n",
              "      <td>37.93125</td>\n",
              "      <td>18.65987</td>\n",
              "      <td>-3.63581</td>\n",
              "      <td>-27.75665</td>\n",
              "      <td>-18.52988</td>\n",
              "      <td>7.76108</td>\n",
              "      <td>3.56109</td>\n",
              "      <td>-2.50351</td>\n",
              "      <td>...</td>\n",
              "      <td>32.38589</td>\n",
              "      <td>-32.75535</td>\n",
              "      <td>-61.05473</td>\n",
              "      <td>56.65182</td>\n",
              "      <td>15.29965</td>\n",
              "      <td>95.88193</td>\n",
              "      <td>-10.63242</td>\n",
              "      <td>12.96552</td>\n",
              "      <td>92.11633</td>\n",
              "      <td>10.88815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515342</th>\n",
              "      <td>2006</td>\n",
              "      <td>45.12852</td>\n",
              "      <td>12.65758</td>\n",
              "      <td>-38.72018</td>\n",
              "      <td>8.80882</td>\n",
              "      <td>-29.29985</td>\n",
              "      <td>-2.28706</td>\n",
              "      <td>-18.40424</td>\n",
              "      <td>-22.28726</td>\n",
              "      <td>-4.52429</td>\n",
              "      <td>...</td>\n",
              "      <td>-18.73598</td>\n",
              "      <td>-71.15954</td>\n",
              "      <td>-123.98443</td>\n",
              "      <td>121.26989</td>\n",
              "      <td>10.89629</td>\n",
              "      <td>34.62409</td>\n",
              "      <td>-248.61020</td>\n",
              "      <td>-6.07171</td>\n",
              "      <td>53.96319</td>\n",
              "      <td>-8.09364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515343</th>\n",
              "      <td>2006</td>\n",
              "      <td>44.16614</td>\n",
              "      <td>32.38368</td>\n",
              "      <td>-3.34971</td>\n",
              "      <td>-2.49165</td>\n",
              "      <td>-19.59278</td>\n",
              "      <td>-18.67098</td>\n",
              "      <td>8.78428</td>\n",
              "      <td>4.02039</td>\n",
              "      <td>-12.01230</td>\n",
              "      <td>...</td>\n",
              "      <td>67.16763</td>\n",
              "      <td>282.77624</td>\n",
              "      <td>-4.63677</td>\n",
              "      <td>144.00125</td>\n",
              "      <td>21.62652</td>\n",
              "      <td>-29.72432</td>\n",
              "      <td>71.47198</td>\n",
              "      <td>20.32240</td>\n",
              "      <td>14.83107</td>\n",
              "      <td>39.74909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515344</th>\n",
              "      <td>2005</td>\n",
              "      <td>51.85726</td>\n",
              "      <td>59.11655</td>\n",
              "      <td>26.39436</td>\n",
              "      <td>-5.46030</td>\n",
              "      <td>-20.69012</td>\n",
              "      <td>-19.95528</td>\n",
              "      <td>-6.72771</td>\n",
              "      <td>2.29590</td>\n",
              "      <td>10.31018</td>\n",
              "      <td>...</td>\n",
              "      <td>-11.50511</td>\n",
              "      <td>-69.18291</td>\n",
              "      <td>60.58456</td>\n",
              "      <td>28.64599</td>\n",
              "      <td>-4.39620</td>\n",
              "      <td>-64.56491</td>\n",
              "      <td>-45.61012</td>\n",
              "      <td>-5.51512</td>\n",
              "      <td>32.35602</td>\n",
              "      <td>12.17352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>515345 rows Ã— 91 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43bad1fe-af8f-4388-a2c8-305d493fbde4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-43bad1fe-af8f-4388-a2c8-305d493fbde4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-43bad1fe-af8f-4388-a2c8-305d493fbde4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaLuAMH_zGrA"
      },
      "source": [
        "To set up our data for classification, we'll use the \"year\" field to represent\n",
        "whether a song was released in the 20-th century. In our case `df[\"year\"]` will be 1 if\n",
        "the year was released after 2000, and 0 otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZdGlNgdzGrA"
      },
      "source": [
        "df[\"year\"] = df[\"year\"].map(lambda x: int(x > 2000))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xugy7FZ8eoAd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "outputId": "83b0c9b4-c775-4fef-cd43-9f42b328d75b"
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    year      var1       var2      var3      var4      var5      var6  \\\n",
              "0      1  49.94357   21.47114  73.07750   8.74861 -17.40628 -13.09905   \n",
              "1      1  48.73215   18.42930  70.32679  12.94636 -10.32437 -24.83777   \n",
              "2      1  50.95714   31.85602  55.81851  13.41693  -6.57898 -18.54940   \n",
              "3      1  48.24750   -1.89837  36.29772   2.58776   0.97170 -26.21683   \n",
              "4      1  50.97020   42.20998  67.09964   8.46791 -15.85279 -16.81409   \n",
              "5      1  50.54767    0.31568  92.35066  22.38696 -25.51870 -19.04928   \n",
              "6      1  50.57546   33.17843  50.53517  11.55217 -27.24764  -8.78206   \n",
              "7      1  48.26892    8.97526  75.23158  24.04945 -16.02105 -14.09491   \n",
              "8      1  49.75468   33.99581  56.73846   2.89581  -2.92429 -26.44413   \n",
              "9      1  45.17809   46.34234 -40.65357  -2.47909   1.21253  -0.65302   \n",
              "10     1  39.13076  -23.01763 -36.20583   1.67519  -4.27101  13.01158   \n",
              "11     1  37.66498  -34.05910 -17.36060 -26.77781 -39.95119 -20.75000   \n",
              "12     1  26.51957 -148.15762 -13.30095  -7.25851  17.22029 -21.99439   \n",
              "13     1  37.68491  -26.84185 -27.10566 -14.95883  -5.87200 -21.68979   \n",
              "14     0  39.11695   -8.29767 -51.37966  -4.42668 -30.06506 -11.95916   \n",
              "15     1  35.05129  -67.97714 -14.20239  -6.68696  -0.61230 -18.70341   \n",
              "16     1  33.63129  -96.14912 -89.38216 -12.11699  13.77252  -6.69377   \n",
              "17     0  41.38639  -20.78665  51.80155  17.21415 -36.44189 -11.53169   \n",
              "18     0  37.45034   11.42615  56.28982  19.58426 -16.43530   2.22457   \n",
              "19     0  39.71092   -4.92800  12.88590 -11.87773   2.48031 -16.11028   \n",
              "\n",
              "        var7      var8      var9  ...     var81      var82      var83  \\\n",
              "0  -25.01202 -12.23257   7.83089  ...  13.01620  -54.40548   58.99367   \n",
              "1    8.76630  -0.92019  18.76548  ...   5.66812  -19.68073   33.04964   \n",
              "2   -3.27872  -2.35035  16.07017  ...   3.03800   26.05866  -50.92779   \n",
              "3    5.05097 -10.34124   3.55005  ...  34.57337 -171.70734  -16.96705   \n",
              "4  -12.48207  -9.37636  12.63699  ...   9.92661  -55.95724   64.92712   \n",
              "5   20.67345  -5.19943   3.63566  ...   6.59753  -50.69577   26.02574   \n",
              "6  -12.04282  -9.53930  28.61811  ...  11.63681   25.44182  134.62382   \n",
              "7    8.11871  -1.87566   7.46701  ...  18.03989  -58.46192  -65.56438   \n",
              "8    1.71392  -0.55644  22.08594  ...  18.70812    5.20391  -27.75192   \n",
              "9   -6.95536 -12.20040  17.02512  ...  -4.36742  -87.55285  -70.79677   \n",
              "10   8.05718  -8.41088   6.27370  ...  32.86051  -26.08461 -186.82429   \n",
              "11  -0.10231  -0.89972  -1.30205  ...  11.18909   45.20614   53.83925   \n",
              "12   5.51947   3.48418   2.61738  ...  23.80442  251.76360   18.81642   \n",
              "13   4.87374 -18.01800   1.52141  ... -67.57637  234.27192  -72.34557   \n",
              "14  -0.85322  -8.86179  11.36680  ...  42.22923  478.26580  -10.33823   \n",
              "15  -1.31928  -9.46370   5.53492  ...  10.25585   94.90539   15.95689   \n",
              "16 -33.36843 -24.81437  21.22757  ...  49.93249  -14.47489   40.70590   \n",
              "17  11.75252  -7.62428  -3.65488  ...  50.37614  -40.48205   48.07805   \n",
              "18   1.02668  -7.34736  -0.01184  ... -22.46207  -25.77228 -322.42841   \n",
              "19 -16.40421  -8.29657   9.86817  ...  11.92816  -73.72412   16.19039   \n",
              "\n",
              "        var84     var85      var86      var87     var88       var89     var90  \n",
              "0    15.37344   1.11144  -23.08793   68.40795  -1.82223   -27.46348   2.26327  \n",
              "1    42.87836  -9.90378  -32.22788   70.49388  12.04941    58.43453  26.92061  \n",
              "2    10.93792  -0.07568   43.20130 -115.00698  -0.05859    39.67068  -0.66345  \n",
              "3   -46.67617 -12.51516   82.58061  -72.08993   9.90558   199.62971  18.85382  \n",
              "4   -17.72522  -1.49237   -7.50035   51.76631   7.88713    55.66926  28.74903  \n",
              "5    18.94430  -0.33730    6.09352   35.18381   5.00283   -11.02257   0.02263  \n",
              "6    21.51982   8.17570   35.46251   11.57736   4.50056    -4.62739   1.40192  \n",
              "7    46.99856  -4.09602   56.37650  -18.29975  -0.30633     3.98364  -3.72556  \n",
              "8    17.22100  -0.85210  -15.67150  -26.36257   5.48708    -9.13495   6.08680  \n",
              "9    76.57355  -7.71727    3.26926 -298.49845  11.49326   -89.21804 -15.09719  \n",
              "10  113.58176   9.28727   44.60282  158.00425  -2.59543   109.19723  23.36143  \n",
              "11    2.59467  -4.00958  -47.74886 -170.92864  -5.19009     8.83617  -7.16056  \n",
              "12  157.09656 -27.79449 -137.72740  115.28414  23.00230  -164.02536  51.54138  \n",
              "13 -362.25101 -25.55019  -89.08971 -891.58937  14.11648 -1030.99180  99.28967  \n",
              "14 -103.76858  39.19511  -98.76636 -122.81061  -2.14942  -211.48202 -12.81569  \n",
              "15  -98.15732  -9.64859  -93.52834  -95.82981  20.73063  -562.07671  43.44696  \n",
              "16   58.63692   8.81522   27.28474    5.78046   3.44539   259.10825  10.28525  \n",
              "17   -7.62399   6.51934  -30.46090  -53.87264   4.44627    58.16913  -0.02409  \n",
              "18 -146.57408  13.61588   92.22918 -439.80259  25.73235   157.22967  38.70617  \n",
              "19    9.79606   9.71693   -9.90907  -20.65851   2.34002   -31.57015   1.58400  \n",
              "\n",
              "[20 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ca2c129-01c4-460d-9340-399727116f79\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>var3</th>\n",
              "      <th>var4</th>\n",
              "      <th>var5</th>\n",
              "      <th>var6</th>\n",
              "      <th>var7</th>\n",
              "      <th>var8</th>\n",
              "      <th>var9</th>\n",
              "      <th>...</th>\n",
              "      <th>var81</th>\n",
              "      <th>var82</th>\n",
              "      <th>var83</th>\n",
              "      <th>var84</th>\n",
              "      <th>var85</th>\n",
              "      <th>var86</th>\n",
              "      <th>var87</th>\n",
              "      <th>var88</th>\n",
              "      <th>var89</th>\n",
              "      <th>var90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>50.54767</td>\n",
              "      <td>0.31568</td>\n",
              "      <td>92.35066</td>\n",
              "      <td>22.38696</td>\n",
              "      <td>-25.51870</td>\n",
              "      <td>-19.04928</td>\n",
              "      <td>20.67345</td>\n",
              "      <td>-5.19943</td>\n",
              "      <td>3.63566</td>\n",
              "      <td>...</td>\n",
              "      <td>6.59753</td>\n",
              "      <td>-50.69577</td>\n",
              "      <td>26.02574</td>\n",
              "      <td>18.94430</td>\n",
              "      <td>-0.33730</td>\n",
              "      <td>6.09352</td>\n",
              "      <td>35.18381</td>\n",
              "      <td>5.00283</td>\n",
              "      <td>-11.02257</td>\n",
              "      <td>0.02263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>50.57546</td>\n",
              "      <td>33.17843</td>\n",
              "      <td>50.53517</td>\n",
              "      <td>11.55217</td>\n",
              "      <td>-27.24764</td>\n",
              "      <td>-8.78206</td>\n",
              "      <td>-12.04282</td>\n",
              "      <td>-9.53930</td>\n",
              "      <td>28.61811</td>\n",
              "      <td>...</td>\n",
              "      <td>11.63681</td>\n",
              "      <td>25.44182</td>\n",
              "      <td>134.62382</td>\n",
              "      <td>21.51982</td>\n",
              "      <td>8.17570</td>\n",
              "      <td>35.46251</td>\n",
              "      <td>11.57736</td>\n",
              "      <td>4.50056</td>\n",
              "      <td>-4.62739</td>\n",
              "      <td>1.40192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>48.26892</td>\n",
              "      <td>8.97526</td>\n",
              "      <td>75.23158</td>\n",
              "      <td>24.04945</td>\n",
              "      <td>-16.02105</td>\n",
              "      <td>-14.09491</td>\n",
              "      <td>8.11871</td>\n",
              "      <td>-1.87566</td>\n",
              "      <td>7.46701</td>\n",
              "      <td>...</td>\n",
              "      <td>18.03989</td>\n",
              "      <td>-58.46192</td>\n",
              "      <td>-65.56438</td>\n",
              "      <td>46.99856</td>\n",
              "      <td>-4.09602</td>\n",
              "      <td>56.37650</td>\n",
              "      <td>-18.29975</td>\n",
              "      <td>-0.30633</td>\n",
              "      <td>3.98364</td>\n",
              "      <td>-3.72556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>49.75468</td>\n",
              "      <td>33.99581</td>\n",
              "      <td>56.73846</td>\n",
              "      <td>2.89581</td>\n",
              "      <td>-2.92429</td>\n",
              "      <td>-26.44413</td>\n",
              "      <td>1.71392</td>\n",
              "      <td>-0.55644</td>\n",
              "      <td>22.08594</td>\n",
              "      <td>...</td>\n",
              "      <td>18.70812</td>\n",
              "      <td>5.20391</td>\n",
              "      <td>-27.75192</td>\n",
              "      <td>17.22100</td>\n",
              "      <td>-0.85210</td>\n",
              "      <td>-15.67150</td>\n",
              "      <td>-26.36257</td>\n",
              "      <td>5.48708</td>\n",
              "      <td>-9.13495</td>\n",
              "      <td>6.08680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>45.17809</td>\n",
              "      <td>46.34234</td>\n",
              "      <td>-40.65357</td>\n",
              "      <td>-2.47909</td>\n",
              "      <td>1.21253</td>\n",
              "      <td>-0.65302</td>\n",
              "      <td>-6.95536</td>\n",
              "      <td>-12.20040</td>\n",
              "      <td>17.02512</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.36742</td>\n",
              "      <td>-87.55285</td>\n",
              "      <td>-70.79677</td>\n",
              "      <td>76.57355</td>\n",
              "      <td>-7.71727</td>\n",
              "      <td>3.26926</td>\n",
              "      <td>-298.49845</td>\n",
              "      <td>11.49326</td>\n",
              "      <td>-89.21804</td>\n",
              "      <td>-15.09719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>39.13076</td>\n",
              "      <td>-23.01763</td>\n",
              "      <td>-36.20583</td>\n",
              "      <td>1.67519</td>\n",
              "      <td>-4.27101</td>\n",
              "      <td>13.01158</td>\n",
              "      <td>8.05718</td>\n",
              "      <td>-8.41088</td>\n",
              "      <td>6.27370</td>\n",
              "      <td>...</td>\n",
              "      <td>32.86051</td>\n",
              "      <td>-26.08461</td>\n",
              "      <td>-186.82429</td>\n",
              "      <td>113.58176</td>\n",
              "      <td>9.28727</td>\n",
              "      <td>44.60282</td>\n",
              "      <td>158.00425</td>\n",
              "      <td>-2.59543</td>\n",
              "      <td>109.19723</td>\n",
              "      <td>23.36143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>37.66498</td>\n",
              "      <td>-34.05910</td>\n",
              "      <td>-17.36060</td>\n",
              "      <td>-26.77781</td>\n",
              "      <td>-39.95119</td>\n",
              "      <td>-20.75000</td>\n",
              "      <td>-0.10231</td>\n",
              "      <td>-0.89972</td>\n",
              "      <td>-1.30205</td>\n",
              "      <td>...</td>\n",
              "      <td>11.18909</td>\n",
              "      <td>45.20614</td>\n",
              "      <td>53.83925</td>\n",
              "      <td>2.59467</td>\n",
              "      <td>-4.00958</td>\n",
              "      <td>-47.74886</td>\n",
              "      <td>-170.92864</td>\n",
              "      <td>-5.19009</td>\n",
              "      <td>8.83617</td>\n",
              "      <td>-7.16056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>26.51957</td>\n",
              "      <td>-148.15762</td>\n",
              "      <td>-13.30095</td>\n",
              "      <td>-7.25851</td>\n",
              "      <td>17.22029</td>\n",
              "      <td>-21.99439</td>\n",
              "      <td>5.51947</td>\n",
              "      <td>3.48418</td>\n",
              "      <td>2.61738</td>\n",
              "      <td>...</td>\n",
              "      <td>23.80442</td>\n",
              "      <td>251.76360</td>\n",
              "      <td>18.81642</td>\n",
              "      <td>157.09656</td>\n",
              "      <td>-27.79449</td>\n",
              "      <td>-137.72740</td>\n",
              "      <td>115.28414</td>\n",
              "      <td>23.00230</td>\n",
              "      <td>-164.02536</td>\n",
              "      <td>51.54138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>37.68491</td>\n",
              "      <td>-26.84185</td>\n",
              "      <td>-27.10566</td>\n",
              "      <td>-14.95883</td>\n",
              "      <td>-5.87200</td>\n",
              "      <td>-21.68979</td>\n",
              "      <td>4.87374</td>\n",
              "      <td>-18.01800</td>\n",
              "      <td>1.52141</td>\n",
              "      <td>...</td>\n",
              "      <td>-67.57637</td>\n",
              "      <td>234.27192</td>\n",
              "      <td>-72.34557</td>\n",
              "      <td>-362.25101</td>\n",
              "      <td>-25.55019</td>\n",
              "      <td>-89.08971</td>\n",
              "      <td>-891.58937</td>\n",
              "      <td>14.11648</td>\n",
              "      <td>-1030.99180</td>\n",
              "      <td>99.28967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>39.11695</td>\n",
              "      <td>-8.29767</td>\n",
              "      <td>-51.37966</td>\n",
              "      <td>-4.42668</td>\n",
              "      <td>-30.06506</td>\n",
              "      <td>-11.95916</td>\n",
              "      <td>-0.85322</td>\n",
              "      <td>-8.86179</td>\n",
              "      <td>11.36680</td>\n",
              "      <td>...</td>\n",
              "      <td>42.22923</td>\n",
              "      <td>478.26580</td>\n",
              "      <td>-10.33823</td>\n",
              "      <td>-103.76858</td>\n",
              "      <td>39.19511</td>\n",
              "      <td>-98.76636</td>\n",
              "      <td>-122.81061</td>\n",
              "      <td>-2.14942</td>\n",
              "      <td>-211.48202</td>\n",
              "      <td>-12.81569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>35.05129</td>\n",
              "      <td>-67.97714</td>\n",
              "      <td>-14.20239</td>\n",
              "      <td>-6.68696</td>\n",
              "      <td>-0.61230</td>\n",
              "      <td>-18.70341</td>\n",
              "      <td>-1.31928</td>\n",
              "      <td>-9.46370</td>\n",
              "      <td>5.53492</td>\n",
              "      <td>...</td>\n",
              "      <td>10.25585</td>\n",
              "      <td>94.90539</td>\n",
              "      <td>15.95689</td>\n",
              "      <td>-98.15732</td>\n",
              "      <td>-9.64859</td>\n",
              "      <td>-93.52834</td>\n",
              "      <td>-95.82981</td>\n",
              "      <td>20.73063</td>\n",
              "      <td>-562.07671</td>\n",
              "      <td>43.44696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>33.63129</td>\n",
              "      <td>-96.14912</td>\n",
              "      <td>-89.38216</td>\n",
              "      <td>-12.11699</td>\n",
              "      <td>13.77252</td>\n",
              "      <td>-6.69377</td>\n",
              "      <td>-33.36843</td>\n",
              "      <td>-24.81437</td>\n",
              "      <td>21.22757</td>\n",
              "      <td>...</td>\n",
              "      <td>49.93249</td>\n",
              "      <td>-14.47489</td>\n",
              "      <td>40.70590</td>\n",
              "      <td>58.63692</td>\n",
              "      <td>8.81522</td>\n",
              "      <td>27.28474</td>\n",
              "      <td>5.78046</td>\n",
              "      <td>3.44539</td>\n",
              "      <td>259.10825</td>\n",
              "      <td>10.28525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>41.38639</td>\n",
              "      <td>-20.78665</td>\n",
              "      <td>51.80155</td>\n",
              "      <td>17.21415</td>\n",
              "      <td>-36.44189</td>\n",
              "      <td>-11.53169</td>\n",
              "      <td>11.75252</td>\n",
              "      <td>-7.62428</td>\n",
              "      <td>-3.65488</td>\n",
              "      <td>...</td>\n",
              "      <td>50.37614</td>\n",
              "      <td>-40.48205</td>\n",
              "      <td>48.07805</td>\n",
              "      <td>-7.62399</td>\n",
              "      <td>6.51934</td>\n",
              "      <td>-30.46090</td>\n",
              "      <td>-53.87264</td>\n",
              "      <td>4.44627</td>\n",
              "      <td>58.16913</td>\n",
              "      <td>-0.02409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>37.45034</td>\n",
              "      <td>11.42615</td>\n",
              "      <td>56.28982</td>\n",
              "      <td>19.58426</td>\n",
              "      <td>-16.43530</td>\n",
              "      <td>2.22457</td>\n",
              "      <td>1.02668</td>\n",
              "      <td>-7.34736</td>\n",
              "      <td>-0.01184</td>\n",
              "      <td>...</td>\n",
              "      <td>-22.46207</td>\n",
              "      <td>-25.77228</td>\n",
              "      <td>-322.42841</td>\n",
              "      <td>-146.57408</td>\n",
              "      <td>13.61588</td>\n",
              "      <td>92.22918</td>\n",
              "      <td>-439.80259</td>\n",
              "      <td>25.73235</td>\n",
              "      <td>157.22967</td>\n",
              "      <td>38.70617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>39.71092</td>\n",
              "      <td>-4.92800</td>\n",
              "      <td>12.88590</td>\n",
              "      <td>-11.87773</td>\n",
              "      <td>2.48031</td>\n",
              "      <td>-16.11028</td>\n",
              "      <td>-16.40421</td>\n",
              "      <td>-8.29657</td>\n",
              "      <td>9.86817</td>\n",
              "      <td>...</td>\n",
              "      <td>11.92816</td>\n",
              "      <td>-73.72412</td>\n",
              "      <td>16.19039</td>\n",
              "      <td>9.79606</td>\n",
              "      <td>9.71693</td>\n",
              "      <td>-9.90907</td>\n",
              "      <td>-20.65851</td>\n",
              "      <td>2.34002</td>\n",
              "      <td>-31.57015</td>\n",
              "      <td>1.58400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows Ã— 91 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ca2c129-01c4-460d-9340-399727116f79')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ca2c129-01c4-460d-9340-399727116f79 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ca2c129-01c4-460d-9340-399727116f79');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncjxI4WdzGrA"
      },
      "source": [
        "### Part (a) -- 7%\n",
        "\n",
        "The data set description text asks us to respect the below train/test split to\n",
        "avoid the \"producer effect\". That is, we want to make sure that no song from a single artist\n",
        "ends up in both the training and test set.\n",
        "\n",
        "Explain why it would be problematic to have\n",
        "some songs from an artist in the training set, and other songs from the same artist in the\n",
        "test set. (Hint: Remember that we want our test accuracy to predict how well the model\n",
        "will perform in practice on a song it hasn't learned about.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NiYlxpFzGrB"
      },
      "source": [
        "df_train = df[:463715]\n",
        "df_test = df[463715:]\n",
        "\n",
        "# convert to numpy\n",
        "train_xs = df_train[x_labels].to_numpy()\n",
        "train_ts = df_train[t_label].to_numpy()\n",
        "test_xs = df_test[x_labels].to_numpy()\n",
        "test_ts = df_test[t_label].to_numpy()\n",
        "\n",
        "# Explanation:\n",
        "# Since most of the songs of an artist were written in the same century, it could be argued that splitting a single artist's song into both \n",
        "# training and testing might lead to an over-confident result as the model might recognize the artist and immidietly classify the song into the dominant century\n",
        "# of the artist. The result is that song's century being classified accorsing on the artist."
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYSzd4XUzGrB"
      },
      "source": [
        "### Part (b) -- 7%\n",
        "\n",
        "It can be beneficial to **normalize** the columns, so that each column (feature)\n",
        "has the *same* mean and standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPuWLksJzGrB"
      },
      "source": [
        "feature_means = df_train.mean()[1:].to_numpy() # the [1:] removes the mean of the \"year\" field\n",
        "feature_stds  = df_train.std()[1:].to_numpy()\n",
        "\n",
        "train_norm_xs = (train_xs - feature_means) / feature_stds\n",
        "test_norm_xs = (test_xs - feature_means) / feature_stds"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4zmZk6ezGrC"
      },
      "source": [
        "Notice how in our code, we normalized the test set using the *training data means and standard deviations*.\n",
        "This is *not* a bug.\n",
        "\n",
        "Explain why it would be improper to compute and use test set means\n",
        "and standard deviations. (Hint: Remember what we want to use the test accuracy to measure.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxZy6brwzGrC"
      },
      "source": [
        "# Explanation:\n",
        "# The splitting between training and testing is \"artificial\" - the testing is supposed to represent the model's performence on new unknown data.\n",
        "# Thus, the only \"known\" parameters are the training parameters - the testing parameters are pretented to be hidden. "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4GqL5J_zGrC"
      },
      "source": [
        "### Part (c) -- 7%\n",
        "\n",
        "Finally, we'll move some of the data in our training set into a validation set.\n",
        "\n",
        "Explain why we should limit how many times we use the test set, and that we should use the validation\n",
        "set during the model building process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsXv1U3gzGrC"
      },
      "source": [
        "# shuffle the training set\n",
        "reindex = np.random.permutation(len(train_xs))\n",
        "train_xs = train_xs[reindex]\n",
        "train_norm_xs = train_norm_xs[reindex]\n",
        "train_ts = train_ts[reindex]\n",
        "\n",
        "# use the first 50000 elements of `train_xs` as the validation set\n",
        "train_xs, val_xs           = train_xs[50000:], train_xs[:50000]\n",
        "train_norm_xs, val_norm_xs = train_norm_xs[50000:], train_norm_xs[:50000]\n",
        "train_ts, val_ts           = train_ts[50000:], train_ts[:50000]\n",
        "\n",
        "# Explanation:\n",
        "# We should limit how many times we use the test data, as we do not want to model to adjust (fit) according to the test data (because it would not allow us to examine\n",
        "# the accuracy and performance of our model later - when using the test set), but rather only to the training set.\n",
        "# In order to validate a specific model structure (and specifically - the hyperparameters) we take a small portion of the training set - namely the \"validation\" set.\n",
        " "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy4lt445zGrD"
      },
      "source": [
        "## Part 2. Classification (79%)\n",
        "\n",
        "We will first build a *classification* model to perform decade classification.\n",
        "These helper functions are written for you. All other code that you write in this section should be vectorized whenever possible (i.e., avoid unnecessary loops)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6BA_s-kzGrD"
      },
      "source": [
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "def cross_entropy(t, y):\n",
        "  return -t * np.log(y) - (1 - t) * np.log(1 - y)\n",
        "\n",
        "def cost(y, t):\n",
        "  return np.mean(cross_entropy(t, y))\n",
        "\n",
        "def get_accuracy(y, t):\n",
        "  acc = 0\n",
        "  N = 0\n",
        "  for i in range(len(y)):\n",
        "    N += 1\n",
        "    if (y[i] >= 0.5 and t[i] == 1) or (y[i] < 0.5 and t[i] == 0):\n",
        "      acc += 1\n",
        "  return acc / N"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8ZIfooBzGrD"
      },
      "source": [
        "### Part (a) -- 7%\n",
        "\n",
        "Write a function `pred` that computes the prediction `y` based on logistic regression, i.e., a single layer with weights `w` and bias `b`. The output is given by: \n",
        "\\begin{equation}\n",
        "y = \\sigma({\\bf w}^T {\\bf x} + b),\n",
        "\\end{equation}\n",
        "where the value of $y$ is an estimate of the probability that the song is released in the current century, namely ${\\rm year} =1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naY5mT4_zGrD"
      },
      "source": [
        "def pred(w, b, X):\n",
        "  \"\"\"\n",
        "  Returns the prediction `y` of the target based on the weights `w` and scalar bias `b`.\n",
        "\n",
        "  Preconditions: np.shape(w) == (90,)\n",
        "                 type(b) == float\n",
        "                 np.shape(X) = (N, 90) for some N\n",
        "\n",
        "  >>> pred(np.zeros(90), 1, np.ones([2, 90]))\n",
        "  array([0.73105858, 0.73105858]) # It's okay if your output differs in the last decimals\n",
        "  \"\"\"\n",
        "  # Code:\n",
        "  return sigmoid(np.transpose(w)@np.transpose(X)+b)\n",
        "\n",
        "# pred(np.zeros(90), 1, np.ones([2, 90]))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxNdmSd3zGrE"
      },
      "source": [
        "### Part (b) -- 7%\n",
        "\n",
        "Write a function `derivative_cost` that computes and returns the gradients \n",
        "$\\frac{\\partial\\mathcal{L}}{\\partial {\\bf w}}$ and\n",
        "$\\frac{\\partial\\mathcal{L}}{\\partial b}$. Here, `X` is the input, `y` is the prediction, and `t` is the true label.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P80bu7qmzGrE"
      },
      "source": [
        "def derivative_cost(X, y, t):\n",
        "  \"\"\"\n",
        "  Returns a tuple containing the gradients dLdw and dLdb.\n",
        "\n",
        "  Precondition: np.shape(X) == (N, 90) for some N\n",
        "                np.shape(y) == (N,)\n",
        "                np.shape(t) == (N,)\n",
        "\n",
        "  Postcondition: np.shape(dLdw) = (90,)\n",
        "           type(dLdb) = float\n",
        "  \"\"\"\n",
        "  # Code:\n",
        "  dLdw = X.T @ (y-t) / (X.shape[0]) \n",
        "  dLdb = np.mean(y - t)\n",
        "  return dLdw , dLdb"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okPRGM3BjKe2"
      },
      "source": [
        "# **Explenation on Gradients**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHfmPVdsg0eX"
      },
      "source": [
        "**Gradients explanation:**\n",
        "\n",
        "In order to calculate the partial derivatives $\\dfrac{\\partial L}{\\partial w}$ and $\\dfrac{\\partial L}{\\partial b}$, we will use the \"Chain-Rule\", as follows:\n",
        "\n",
        "$$\\dfrac{\\partial L}{\\partial w}=\\dfrac{\\partial L}{\\partial y_n}\\cdot \\dfrac{\\partial y_n}{\\partial z_n}\\cdot \\dfrac{\\partial z_n}{\\partial w}$$\n",
        "\n",
        "$$ \\dfrac{\\partial L}{\\partial b}=\\dfrac{\\partial L}{\\partial y_n}\\cdot \\dfrac{\\partial y_n}{\\partial z_n}\\cdot \\dfrac{\\partial z_n}{\\partial b}$$\n",
        "\n",
        "For that purpose, shown below are the functions explicitly, with the corresponding arguments:\n",
        "$$L(y_n)= \\frac{1}{N}\\sum_{n=1}^{N} \\left[-t_n\\cdot log(y_n)-(1-t_n)\\cdot log(1-y_n) \\right]$$\n",
        "$$y_n(z_n)= \\frac{1}{1+e^{-z_n}}$$\n",
        "$$z_n(w)= w^T\\cdot x_n + b$$\n",
        "\n",
        "This allows calculating each derivative separately in the following manner:\n",
        "$$\\dfrac{\\partial L}{\\partial y_n} =\\frac{1}{N}\\sum_{n=1}^{N} \\left[ \\frac{-t_n}{y_n}+\\frac{1-t_n}{1-y_n} \\right] $$\n",
        "\n",
        "$$\\dfrac{\\partial y_n}{\\partial z_n} = -1(1+e^{-z_n})^{-2}\\cdot (-e^{-z_n}) = \\frac{1}{e^{z_n}(1+e^{-z_n})}\\cdot \\frac{1}{1+e^{-z_n}}=(1-y_n)\\cdot y_n $$\n",
        "$$\\dfrac{\\partial z_n}{\\partial w} = x_n $$\n",
        "$$\\dfrac{\\partial z_n}{\\partial b} = 1 $$\n",
        "\n",
        "Plugging these results gives:\n",
        "\n",
        "$$ \\dfrac{\\partial L}{\\partial w}=\\frac{1}{N}\\sum_{n=1}^{N} \\left[(-t_n(1-y_n)+(1-t_n)y_n)\\cdot x_n \\right] = \\frac{1}{N}\\sum_{n=1}^{N} \\left[(y_n-t_n)\\cdot x_n \\right] $$\n",
        "$$ \\dfrac{\\partial L}{\\partial b}=\\frac{1}{N}\\sum_{n=1}^{N} \\left[(-t_n(1-y_n)+(1-t_n)y_n) \\right] = \\frac{1}{N}\\sum_{n=1}^{N} \\left[(y_n-t_n) \\right] $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhQXAKd4zGrE"
      },
      "source": [
        "### Part (c) -- 7%\n",
        "\n",
        "We can check that our derivative is implemented correctly using the finite difference rule. In 1D, the\n",
        "finite difference rule tells us that for small $h$, we should have\n",
        "\n",
        "$$\\frac{f(x+h) - f(x)}{h} \\approx f'(x)$$\n",
        "\n",
        "Show that $\\frac{\\partial\\mathcal{L}}{\\partial b}$  is implement correctly\n",
        "by comparing the result from `derivative_cost` with the empirical cost derivative computed using the above numerical approximation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpRTD-fozGrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863b251f-06b4-456f-f74b-1192f5dd2ae7"
      },
      "source": [
        "# Code\n",
        "\n",
        "N = 10\n",
        "h = 1e-5\n",
        "\n",
        "X = train_norm_xs[0:N,:]\n",
        "t = train_ts[0:N,0]\n",
        "w = np.zeros(90)\n",
        "b = 1\n",
        "\n",
        "\n",
        "y_0 = pred (w, b, X)\n",
        "y_1 = pred (w, b+h, X)\n",
        "\n",
        "r1 = (cost(y_1,t)-cost(y_0,t))/h\n",
        "_ , r2 = derivative_cost(X, y_0, t)\n",
        "\n",
        "print(\"The analytical results is -\", r1)\n",
        "print(\"The algorithm results is - \", r2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The analytical results is - 0.1310595617032284\n",
            "The algorithm results is -  0.13105857863000486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTiplTPhzGrF"
      },
      "source": [
        "### Part (d) -- 7%\n",
        "\n",
        "Show that $\\frac{\\partial\\mathcal{L}}{\\partial {\\bf w}}$  is implement correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVTsHgnPzGrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9938bd27-5b56-4cfc-a268-01c39343ead4"
      },
      "source": [
        "# Code:\n",
        "H = np.zeros(90)\n",
        "r1 = np.zeros(90)\n",
        "\n",
        "for ii in range(w.shape[0]):\n",
        "  H[ii] = h\n",
        "  y_1 = pred (w+H, b, X)\n",
        "  r1_i = (cost(y_1,t)-cost(y_0,t))/h\n",
        "  H[ii] = 0\n",
        "  r1[ii]=r1_i\n",
        "r2 , _ = derivative_cost(X, y_0, t)\n",
        "\n",
        "print(\"The analytical results is -\", r1)\n",
        "print(\"The algorithm results is - \", r2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The analytical results is - [ 0.02105917  0.13584851  0.0700123   0.00584569  0.17979957  0.20200362\n",
            " -0.06860999 -0.06963814  0.00137698 -0.0888791  -0.29336001 -0.04689994\n",
            " -0.00177798 -0.00706029 -0.1046164  -0.00926356  0.05699031  0.06002968\n",
            " -0.02956979  0.03171786  0.15797105  0.07240723  0.01754647  0.02871803\n",
            "  0.2123074   0.02114716 -0.11011304 -0.06820226  0.09902801  0.16952842\n",
            "  0.00814668  0.16848368  0.03190714  0.03272532  0.05121305  0.16201037\n",
            " -0.16055233  0.06144419 -0.09983979  0.10376674 -0.10381041  0.03664326\n",
            " -0.11420147  0.21162639  0.24948929 -0.14716717 -0.15431085 -0.13694618\n",
            "  0.07696177  0.08474097 -0.13411621 -0.30030191  0.03757417  0.17514245\n",
            "  0.12387826 -0.11493543 -0.02855141 -0.15250892  0.00373346 -0.10195022\n",
            "  0.10801735 -0.07015357 -0.11959978 -0.13068053  0.15139228 -0.12607766\n",
            " -0.14263008 -0.05597422 -0.18062842 -0.18682967  0.14517107  0.23408518\n",
            "  0.10611402  0.13939296  0.02401878  0.16243346  0.00205547  0.21158607\n",
            " -0.14336262  0.263773   -0.02472872  0.14992717  0.13533202  0.0497959\n",
            "  0.16374192  0.16200812  0.10637676  0.00907977  0.05494339  0.05826663]\n",
            "The algorithm results is -  [ 0.02105806  0.13584729  0.07001033  0.00584527  0.17979822  0.20200285\n",
            " -0.06861071 -0.06963887  0.00137648 -0.0888798  -0.29336166 -0.04690028\n",
            " -0.00177824 -0.00706067 -0.10461668 -0.00926424  0.05698939  0.06002901\n",
            " -0.02957027  0.03171729  0.15797048  0.07240635  0.01754585  0.02871753\n",
            "  0.21230546  0.02114691 -0.1101137  -0.06820344  0.09902744  0.16952787\n",
            "  0.0081462   0.16848341  0.03190634  0.03272508  0.05121264  0.16200922\n",
            " -0.16055349  0.06144284 -0.09984138  0.10376578 -0.10381137  0.03664261\n",
            " -0.11420284  0.21162527  0.2494886  -0.14716839 -0.15431209 -0.13694674\n",
            "  0.07696102  0.08474035 -0.13411718 -0.30030256  0.03757382  0.17514171\n",
            "  0.12387672 -0.11493653 -0.02855238 -0.1525092   0.00373237 -0.10195043\n",
            "  0.10801666 -0.07015391 -0.11960106 -0.13068123  0.15139189 -0.12607873\n",
            " -0.1426305  -0.05597568 -0.18062891 -0.18683128  0.14516984  0.23408452\n",
            "  0.10611379  0.13939203  0.02401835  0.162433    0.00205382  0.21158504\n",
            " -0.14336417  0.2637718  -0.02473031  0.14992537  0.13533178  0.04979555\n",
            "  0.16374014  0.16200716  0.10637635  0.00907798  0.05494307  0.05826578]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgBTPF_2zGrG"
      },
      "source": [
        "### Part (e) -- 7%\n",
        "\n",
        "Now that you have a gradient function that works, we can actually run gradient descent. \n",
        "Complete the following code that will run stochastic: gradient descent training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW4DEuuPzGrG"
      },
      "source": [
        "def run_gradient_descent(train_norm_xs, train_ts, val_norm_xs, val_ts, w0, b0, mu=0.1, batch_size=100, max_iters=100):\n",
        "  \"\"\"Return the values of (w, b) after running gradient descent for max_iters.\n",
        "  We use:\n",
        "    - train_norm_xs and train_ts as the training set\n",
        "    - val_norm_xs and val_ts as the test set\n",
        "    - mu as the learning rate\n",
        "    - (w0, b0) as the initial values of (w, b)\n",
        "\n",
        "  Precondition: np.shape(w0) == (90,)\n",
        "                type(b0) == float\n",
        " \n",
        "  Postcondition: np.shape(w) == (90,)\n",
        "                 type(b) == float\n",
        "  \"\"\"\n",
        "  w = w0\n",
        "  b = b0\n",
        "  iter = 0\n",
        "  val_log = {'accuracy': [], 'cost': []}\n",
        "\n",
        "  while iter < max_iters:\n",
        "    # shuffle the training set:\n",
        "    reindex = np.random.permutation(len(train_norm_xs))\n",
        "    train_norm_xs = train_norm_xs[reindex]\n",
        "    train_ts = train_ts[reindex]\n",
        "\n",
        "    for i in range(0, len(train_norm_xs), batch_size): # iterate over each minibatch\n",
        "      # minibatch that we are working with:\n",
        "      X = train_norm_xs[i:(i + batch_size)]\n",
        "      t = train_ts[i:(i + batch_size), 0]\n",
        "\n",
        "      # since len(train_norm_xs) does not divide batch_size evenly, we will skip over\n",
        "      # the \"last\" minibatch\n",
        "      if np.shape(X)[0] != batch_size:\n",
        "        continue\n",
        "      \n",
        "      # compute the prediction\n",
        "      y = pred (w,b,X)\n",
        "\n",
        "      # update w and b\n",
        "      dLdw , dLdb = derivative_cost(X, y, t)\n",
        "      w += -mu*dLdw\n",
        "      b += -mu*dLdb\n",
        "\n",
        "      # increment the iteration count\n",
        "      iter += 1\n",
        "      # compute and print the *validation* loss and accuracy\n",
        "      if (iter % 10 == 0):\n",
        "        val_y = pred(w,b,val_norm_xs)\n",
        "        val_cost = cost(val_y,val_ts)\n",
        "        val_acc = get_accuracy(val_y, val_ts)\n",
        "        print(\"Iter %d. [Val Acc %.0f%%, Loss %f]\" % (\n",
        "                iter, val_acc * 100, val_cost))\n",
        "        # Log validation data\n",
        "        val_log[\"accuracy\"].append(val_acc*100)\n",
        "        val_log[\"cost\"].append(val_cost)\n",
        "\n",
        "      if iter >= max_iters:\n",
        "        break\n",
        "\n",
        "      # Think what parameters you should return for further use\n",
        "      \n",
        "  return val_log\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MqzT0jGzGrH"
      },
      "source": [
        "### Part (f) -- 7%\n",
        "\n",
        "Call `run_gradient_descent` with the weights and biases all initialized to zero.\n",
        "Show that if the learning rate $\\mu$ is too small, then convergence is slow.\n",
        "Also, show that if $\\mu$ is too large, then the optimization algorirthm does not converge. The demonstration should be made using plots showing these effects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE32Iqo6zGrH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88c84ec9-16e4-425a-c5c7-7590f4c1f5c9"
      },
      "source": [
        "# Code:\n",
        "w0 = np.zeros(90)\n",
        "b0 = np.zeros(1)[0]\n",
        "mu_vec = [1e-3, 1e-2, 1e-0]\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize=(10, 5))\n",
        "iter=250;\n",
        "\n",
        "\n",
        "for mu in mu_vec:\n",
        "  print('mu = ',mu)\n",
        "  # log = run_gradient_descent(train_norm_xs[:100000], train_ts[:100000], val_norm_xs[:5000],val_ts[:5000], w0, b0, mu, batch_size=100, max_iters=iter)\n",
        "  log = run_gradient_descent(train_norm_xs, train_ts, val_norm_xs[:1000],val_ts[:1000], w0, b0, mu, batch_size=100, max_iters=iter)\n",
        "  ax[0].plot(np.arange(0,iter,10),log[\"accuracy\"][:],label = \"$\\mu$ = \"+str(mu))\n",
        "  ax[1].plot(np.arange(0,iter,10),log[\"cost\"][:],label = \"$\\mu$ = \"+str(mu))\n",
        "\n",
        "ax[0].set_xlabel('# Iteration')\n",
        "ax[0].set_ylabel('[%]')\n",
        "ax[1].set_xlabel('# Iteration')\n",
        "ax[0].set_title('Accuracy')\n",
        "ax[1].set_title('Loss')\n",
        "ax[1].legend(loc='center left')\n",
        "ax[0].grid()\n",
        "ax[1].grid()\n",
        "plt.show()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mu =  0.001\n",
            "Iter 10. [Val Acc 64%, Loss 0.693122]\n",
            "Iter 20. [Val Acc 64%, Loss 0.693109]\n",
            "Iter 30. [Val Acc 65%, Loss 0.693094]\n",
            "Iter 40. [Val Acc 65%, Loss 0.693092]\n",
            "Iter 50. [Val Acc 65%, Loss 0.693093]\n",
            "Iter 60. [Val Acc 65%, Loss 0.693112]\n",
            "Iter 70. [Val Acc 65%, Loss 0.693116]\n",
            "Iter 80. [Val Acc 65%, Loss 0.693155]\n",
            "Iter 90. [Val Acc 65%, Loss 0.693184]\n",
            "Iter 100. [Val Acc 66%, Loss 0.693204]\n",
            "Iter 110. [Val Acc 66%, Loss 0.693254]\n",
            "Iter 120. [Val Acc 66%, Loss 0.693286]\n",
            "Iter 130. [Val Acc 65%, Loss 0.693292]\n",
            "Iter 140. [Val Acc 66%, Loss 0.693344]\n",
            "Iter 150. [Val Acc 66%, Loss 0.693363]\n",
            "Iter 160. [Val Acc 66%, Loss 0.693398]\n",
            "Iter 170. [Val Acc 66%, Loss 0.693464]\n",
            "Iter 180. [Val Acc 66%, Loss 0.693534]\n",
            "Iter 190. [Val Acc 66%, Loss 0.693575]\n",
            "Iter 200. [Val Acc 66%, Loss 0.693658]\n",
            "Iter 210. [Val Acc 66%, Loss 0.693731]\n",
            "Iter 220. [Val Acc 66%, Loss 0.693795]\n",
            "Iter 230. [Val Acc 67%, Loss 0.693881]\n",
            "Iter 240. [Val Acc 67%, Loss 0.693957]\n",
            "Iter 250. [Val Acc 66%, Loss 0.694037]\n",
            "mu =  0.01\n",
            "Iter 10. [Val Acc 68%, Loss 0.695358]\n",
            "Iter 20. [Val Acc 68%, Loss 0.696271]\n",
            "Iter 30. [Val Acc 67%, Loss 0.697576]\n",
            "Iter 40. [Val Acc 67%, Loss 0.698181]\n",
            "Iter 50. [Val Acc 66%, Loss 0.699335]\n",
            "Iter 60. [Val Acc 68%, Loss 0.700873]\n",
            "Iter 70. [Val Acc 69%, Loss 0.702672]\n",
            "Iter 80. [Val Acc 69%, Loss 0.703192]\n",
            "Iter 90. [Val Acc 69%, Loss 0.704624]\n",
            "Iter 100. [Val Acc 68%, Loss 0.705733]\n",
            "Iter 110. [Val Acc 69%, Loss 0.706889]\n",
            "Iter 120. [Val Acc 69%, Loss 0.707598]\n",
            "Iter 130. [Val Acc 69%, Loss 0.707833]\n",
            "Iter 140. [Val Acc 70%, Loss 0.708755]\n",
            "Iter 150. [Val Acc 70%, Loss 0.711686]\n",
            "Iter 160. [Val Acc 69%, Loss 0.713237]\n",
            "Iter 170. [Val Acc 69%, Loss 0.714268]\n",
            "Iter 180. [Val Acc 69%, Loss 0.715561]\n",
            "Iter 190. [Val Acc 69%, Loss 0.716208]\n",
            "Iter 200. [Val Acc 70%, Loss 0.718552]\n",
            "Iter 210. [Val Acc 70%, Loss 0.719266]\n",
            "Iter 220. [Val Acc 70%, Loss 0.719123]\n",
            "Iter 230. [Val Acc 69%, Loss 0.720235]\n",
            "Iter 240. [Val Acc 69%, Loss 0.723081]\n",
            "Iter 250. [Val Acc 69%, Loss 0.724086]\n",
            "mu =  1.0\n",
            "Iter 10. [Val Acc 64%, Loss 0.908429]\n",
            "Iter 20. [Val Acc 59%, Loss 1.140746]\n",
            "Iter 30. [Val Acc 68%, Loss 1.042726]\n",
            "Iter 40. [Val Acc 67%, Loss 0.977084]\n",
            "Iter 50. [Val Acc 69%, Loss 0.950365]\n",
            "Iter 60. [Val Acc 68%, Loss 1.025566]\n",
            "Iter 70. [Val Acc 70%, Loss 0.997250]\n",
            "Iter 80. [Val Acc 68%, Loss 0.956341]\n",
            "Iter 90. [Val Acc 71%, Loss 0.983394]\n",
            "Iter 100. [Val Acc 69%, Loss 0.965159]\n",
            "Iter 110. [Val Acc 71%, Loss 0.988626]\n",
            "Iter 120. [Val Acc 68%, Loss 1.036124]\n",
            "Iter 130. [Val Acc 69%, Loss 1.008950]\n",
            "Iter 140. [Val Acc 69%, Loss 0.948825]\n",
            "Iter 150. [Val Acc 68%, Loss 0.991713]\n",
            "Iter 160. [Val Acc 68%, Loss 0.969249]\n",
            "Iter 170. [Val Acc 70%, Loss 0.941646]\n",
            "Iter 180. [Val Acc 67%, Loss 0.951200]\n",
            "Iter 190. [Val Acc 67%, Loss 0.990628]\n",
            "Iter 200. [Val Acc 69%, Loss 0.990886]\n",
            "Iter 210. [Val Acc 69%, Loss 0.994100]\n",
            "Iter 220. [Val Acc 67%, Loss 1.118888]\n",
            "Iter 230. [Val Acc 70%, Loss 1.020081]\n",
            "Iter 240. [Val Acc 70%, Loss 1.046710]\n",
            "Iter 250. [Val Acc 69%, Loss 1.067434]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S44GmUZ12o-g"
      },
      "source": [
        "**Explain and discuss your results here:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ5HlDFAzGrH"
      },
      "source": [
        "### Part (g) -- 7%\n",
        "\n",
        "Find the optimial value of ${\\bf w}$ and $b$ using your code. Explain how you chose\n",
        "the learning rate $\\mu$ and the batch size. Show plots demostrating good and bad behaviours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dFOFSwgzGrI"
      },
      "source": [
        "w0 = np.random.randn(90)\n",
        "b0 = np.random.randn(1)[0]\n",
        "\n",
        "# Write your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkZt7_932zX2"
      },
      "source": [
        "**Explain and discuss your results here:**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KrQqSj2zGrI"
      },
      "source": [
        "### Part (h) -- 15%\n",
        "\n",
        "Using the values of `w` and `b` from part (g), compute your training accuracy, validation accuracy,\n",
        "and test accuracy. Are there any differences between those three values? If so, why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuKw2mLozGrI"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "train_acc = ...\n",
        "val_acc = ...\n",
        "test_acc = ...\n",
        "\n",
        "print('train_acc = ', train_acc, ' val_acc = ', val_acc, ' test_acc = ', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXZa1u6920M3"
      },
      "source": [
        "**Explain and discuss your results here:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4eP2Yh1zGrI"
      },
      "source": [
        "### Part (i) -- 15%\n",
        "\n",
        "Writing a classifier like this is instructive, and helps you understand what happens when\n",
        "we train a model. However, in practice, we rarely write model building and training code\n",
        "from scratch. Instead, we typically use one of the well-tested libraries available in a package.\n",
        "\n",
        "Use `sklearn.linear_model.LogisticRegression` to build a linear classifier, and make predictions about the test set. Start by reading the\n",
        "[API documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
        "\n",
        "Compute the training, validation and test accuracy of this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24LCfAa1zGrJ"
      },
      "source": [
        "import sklearn.linear_model\n",
        "\n",
        "model = ...\n",
        "\n",
        "train_acc = ...\n",
        "val_acc = ...\n",
        "test_acc = ...\n",
        "\n",
        "print('train_acc = ', train_acc, ' val_acc = ', val_acc, ' test_acc = ', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRqucdV923tG"
      },
      "source": [
        "**This parts helps by checking if the code worked.**\n",
        "**Check if you get similar results, if not repair your code**\n"
      ]
    }
  ]
}